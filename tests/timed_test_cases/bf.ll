; ModuleID = 'bf.c'
source_filename = "bf.c"
target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-macosx10.13.0"

@bf_init_P = constant [18 x i64] [i64 608135816, i64 2242054355, i64 320440878, i64 57701188, i64 2752067618, i64 698298832, i64 137296536, i64 3964562569, i64 1160258022, i64 953160567, i64 3193202383, i64 887688300, i64 3232508343, i64 3380367581, i64 1065670069, i64 3041331479, i64 2450970073, i64 2306472731], align 16
@bf_init_S = constant [1024 x i64] [i64 3509652390, i64 2564797868, i64 805139163, i64 3491422135, i64 3101798381, i64 1780907670, i64 3128725573, i64 4046225305, i64 614570311, i64 3012652279, i64 134345442, i64 2240740374, i64 1667834072, i64 1901547113, i64 2757295779, i64 4103290238, i64 227898511, i64 1921955416, i64 1904987480, i64 2182433518, i64 2069144605, i64 3260701109, i64 2620446009, i64 720527379, i64 3318853667, i64 677414384, i64 3393288472, i64 3101374703, i64 2390351024, i64 1614419982, i64 1822297739, i64 2954791486, i64 3608508353, i64 3174124327, i64 2024746970, i64 1432378464, i64 3864339955, i64 2857741204, i64 1464375394, i64 1676153920, i64 1439316330, i64 715854006, i64 3033291828, i64 289532110, i64 2706671279, i64 2087905683, i64 3018724369, i64 1668267050, i64 732546397, i64 1947742710, i64 3462151702, i64 2609353502, i64 2950085171, i64 1814351708, i64 2050118529, i64 680887927, i64 999245976, i64 1800124847, i64 3300911131, i64 1713906067, i64 1641548236, i64 4213287313, i64 1216130144, i64 1575780402, i64 4018429277, i64 3917837745, i64 3693486850, i64 3949271944, i64 596196993, i64 3549867205, i64 258830323, i64 2213823033, i64 772490370, i64 2760122372, i64 1774776394, i64 2652871518, i64 566650946, i64 4142492826, i64 1728879713, i64 2882767088, i64 1783734482, i64 3629395816, i64 2517608232, i64 2874225571, i64 1861159788, i64 326777828, i64 3124490320, i64 2130389656, i64 2716951837, i64 967770486, i64 1724537150, i64 2185432712, i64 2364442137, i64 1164943284, i64 2105845187, i64 998989502, i64 3765401048, i64 2244026483, i64 1075463327, i64 1455516326, i64 1322494562, i64 910128902, i64 469688178, i64 1117454909, i64 936433444, i64 3490320968, i64 3675253459, i64 1240580251, i64 122909385, i64 2157517691, i64 634681816, i64 4142456567, i64 3825094682, i64 3061402683, i64 2540495037, i64 79693498, i64 3249098678, i64 1084186820, i64 1583128258, i64 426386531, i64 1761308591, i64 1047286709, i64 322548459, i64 995290223, i64 1845252383, i64 2603652396, i64 3431023940, i64 2942221577, i64 3202600964, i64 3727903485, i64 1712269319, i64 422464435, i64 3234572375, i64 1170764815, i64 3523960633, i64 3117677531, i64 1434042557, i64 442511882, i64 3600875718, i64 1076654713, i64 1738483198, i64 4213154764, i64 2393238008, i64 3677496056, i64 1014306527, i64 4251020053, i64 793779912, i64 2902807211, i64 842905082, i64 4246964064, i64 1395751752, i64 1040244610, i64 2656851899, i64 3396308128, i64 445077038, i64 3742853595, i64 3577915638, i64 679411651, i64 2892444358, i64 2354009459, i64 1767581616, i64 3150600392, i64 3791627101, i64 3102740896, i64 284835224, i64 4246832056, i64 1258075500, i64 768725851, i64 2589189241, i64 3069724005, i64 3532540348, i64 1274779536, i64 3789419226, i64 2764799539, i64 1660621633, i64 3471099624, i64 4011903706, i64 913787905, i64 3497959166, i64 737222580, i64 2514213453, i64 2928710040, i64 3937242737, i64 1804850592, i64 3499020752, i64 2949064160, i64 2386320175, i64 2390070455, i64 2415321851, i64 4061277028, i64 2290661394, i64 2416832540, i64 1336762016, i64 1754252060, i64 3520065937, i64 3014181293, i64 791618072, i64 3188594551, i64 3933548030, i64 2332172193, i64 3852520463, i64 3043980520, i64 413987798, i64 3465142937, i64 3030929376, i64 4245938359, i64 2093235073, i64 3534596313, i64 375366246, i64 2157278981, i64 2479649556, i64 555357303, i64 3870105701, i64 2008414854, i64 3344188149, i64 4221384143, i64 3956125452, i64 2067696032, i64 3594591187, i64 2921233993, i64 2428461, i64 544322398, i64 577241275, i64 1471733935, i64 610547355, i64 4027169054, i64 1432588573, i64 1507829418, i64 2025931657, i64 3646575487, i64 545086370, i64 48609733, i64 2200306550, i64 1653985193, i64 298326376, i64 1316178497, i64 3007786442, i64 2064951626, i64 458293330, i64 2589141269, i64 3591329599, i64 3164325604, i64 727753846, i64 2179363840, i64 146436021, i64 1461446943, i64 4069977195, i64 705550613, i64 3059967265, i64 3887724982, i64 4281599278, i64 3313849956, i64 1404054877, i64 2845806497, i64 146425753, i64 1854211946, i64 1266315497, i64 3048417604, i64 3681880366, i64 3289982499, i64 2909710000, i64 1235738493, i64 2632868024, i64 2414719590, i64 3970600049, i64 1771706367, i64 1449415276, i64 3266420449, i64 422970021, i64 1963543593, i64 2690192192, i64 3826793022, i64 1062508698, i64 1531092325, i64 1804592342, i64 2583117782, i64 2714934279, i64 4024971509, i64 1294809318, i64 4028980673, i64 1289560198, i64 2221992742, i64 1669523910, i64 35572830, i64 157838143, i64 1052438473, i64 1016535060, i64 1802137761, i64 1753167236, i64 1386275462, i64 3080475397, i64 2857371447, i64 1040679964, i64 2145300060, i64 2390574316, i64 1461121720, i64 2956646967, i64 4031777805, i64 4028374788, i64 33600511, i64 2920084762, i64 1018524850, i64 629373528, i64 3691585981, i64 3515945977, i64 2091462646, i64 2486323059, i64 586499841, i64 988145025, i64 935516892, i64 3367335476, i64 2599673255, i64 2839830854, i64 265290510, i64 3972581182, i64 2759138881, i64 3795373465, i64 1005194799, i64 847297441, i64 406762289, i64 1314163512, i64 1332590856, i64 1866599683, i64 4127851711, i64 750260880, i64 613907577, i64 1450815602, i64 3165620655, i64 3734664991, i64 3650291728, i64 3012275730, i64 3704569646, i64 1427272223, i64 778793252, i64 1343938022, i64 2676280711, i64 2052605720, i64 1946737175, i64 3164576444, i64 3914038668, i64 3967478842, i64 3682934266, i64 1661551462, i64 3294938066, i64 4011595847, i64 840292616, i64 3712170807, i64 616741398, i64 312560963, i64 711312465, i64 1351876610, i64 322626781, i64 1910503582, i64 271666773, i64 2175563734, i64 1594956187, i64 70604529, i64 3617834859, i64 1007753275, i64 1495573769, i64 4069517037, i64 2549218298, i64 2663038764, i64 504708206, i64 2263041392, i64 3941167025, i64 2249088522, i64 1514023603, i64 1998579484, i64 1312622330, i64 694541497, i64 2582060303, i64 2151582166, i64 1382467621, i64 776784248, i64 2618340202, i64 3323268794, i64 2497899128, i64 2784771155, i64 503983604, i64 4076293799, i64 907881277, i64 423175695, i64 432175456, i64 1378068232, i64 4145222326, i64 3954048622, i64 3938656102, i64 3820766613, i64 2793130115, i64 2977904593, i64 26017576, i64 3274890735, i64 3194772133, i64 1700274565, i64 1756076034, i64 4006520079, i64 3677328699, i64 720338349, i64 1533947780, i64 354530856, i64 688349552, i64 3973924725, i64 1637815568, i64 332179504, i64 3949051286, i64 53804574, i64 2852348879, i64 3044236432, i64 1282449977, i64 3583942155, i64 3416972820, i64 4006381244, i64 1617046695, i64 2628476075, i64 3002303598, i64 1686838959, i64 431878346, i64 2686675385, i64 1700445008, i64 1080580658, i64 1009431731, i64 832498133, i64 3223435511, i64 2605976345, i64 2271191193, i64 2516031870, i64 1648197032, i64 4164389018, i64 2548247927, i64 300782431, i64 375919233, i64 238389289, i64 3353747414, i64 2531188641, i64 2019080857, i64 1475708069, i64 455242339, i64 2609103871, i64 448939670, i64 3451063019, i64 1395535956, i64 2413381860, i64 1841049896, i64 1491858159, i64 885456874, i64 4264095073, i64 4001119347, i64 1565136089, i64 3898914787, i64 1108368660, i64 540939232, i64 1173283510, i64 2745871338, i64 3681308437, i64 4207628240, i64 3343053890, i64 4016749493, i64 1699691293, i64 1103962373, i64 3625875870, i64 2256883143, i64 3830138730, i64 1031889488, i64 3479347698, i64 1535977030, i64 4236805024, i64 3251091107, i64 2132092099, i64 1774941330, i64 1199868427, i64 1452454533, i64 157007616, i64 2904115357, i64 342012276, i64 595725824, i64 1480756522, i64 206960106, i64 497939518, i64 591360097, i64 863170706, i64 2375253569, i64 3596610801, i64 1814182875, i64 2094937945, i64 3421402208, i64 1082520231, i64 3463918190, i64 2785509508, i64 435703966, i64 3908032597, i64 1641649973, i64 2842273706, i64 3305899714, i64 1510255612, i64 2148256476, i64 2655287854, i64 3276092548, i64 4258621189, i64 236887753, i64 3681803219, i64 274041037, i64 1734335097, i64 3815195456, i64 3317970021, i64 1899903192, i64 1026095262, i64 4050517792, i64 356393447, i64 2410691914, i64 3873677099, i64 3682840055, i64 3913112168, i64 2491498743, i64 4132185628, i64 2489919796, i64 1091903735, i64 1979897079, i64 3170134830, i64 3567386728, i64 3557303409, i64 857797738, i64 1136121015, i64 1342202287, i64 507115054, i64 2535736646, i64 337727348, i64 3213592640, i64 1301675037, i64 2528481711, i64 1895095763, i64 1721773893, i64 3216771564, i64 62756741, i64 2142006736, i64 835421444, i64 2531993523, i64 1442658625, i64 3659876326, i64 2882144922, i64 676362277, i64 1392781812, i64 170690266, i64 3921047035, i64 1759253602, i64 3611846912, i64 1745797284, i64 664899054, i64 1329594018, i64 3901205900, i64 3045908486, i64 2062866102, i64 2865634940, i64 3543621612, i64 3464012697, i64 1080764994, i64 553557557, i64 3656615353, i64 3996768171, i64 991055499, i64 499776247, i64 1265440854, i64 648242737, i64 3940784050, i64 980351604, i64 3713745714, i64 1749149687, i64 3396870395, i64 4211799374, i64 3640570775, i64 1161844396, i64 3125318951, i64 1431517754, i64 545492359, i64 4268468663, i64 3499529547, i64 1437099964, i64 2702547544, i64 3433638243, i64 2581715763, i64 2787789398, i64 1060185593, i64 1593081372, i64 2418618748, i64 4260947970, i64 69676912, i64 2159744348, i64 86519011, i64 2512459080, i64 3838209314, i64 1220612927, i64 3339683548, i64 133810670, i64 1090789135, i64 1078426020, i64 1569222167, i64 845107691, i64 3583754449, i64 4072456591, i64 1091646820, i64 628848692, i64 1613405280, i64 3757631651, i64 526609435, i64 236106946, i64 48312990, i64 2942717905, i64 3402727701, i64 1797494240, i64 859738849, i64 992217954, i64 4005476642, i64 2243076622, i64 3870952857, i64 3732016268, i64 765654824, i64 3490871365, i64 2511836413, i64 1685915746, i64 3888969200, i64 1414112111, i64 2273134842, i64 3281911079, i64 4080962846, i64 172450625, i64 2569994100, i64 980381355, i64 4109958455, i64 2819808352, i64 2716589560, i64 2568741196, i64 3681446669, i64 3329971472, i64 1835478071, i64 660984891, i64 3704678404, i64 4045999559, i64 3422617507, i64 3040415634, i64 1762651403, i64 1719377915, i64 3470491036, i64 2693910283, i64 3642056355, i64 3138596744, i64 1364962596, i64 2073328063, i64 1983633131, i64 926494387, i64 3423689081, i64 2150032023, i64 4096667949, i64 1749200295, i64 3328846651, i64 309677260, i64 2016342300, i64 1779581495, i64 3079819751, i64 111262694, i64 1274766160, i64 443224088, i64 298511866, i64 1025883608, i64 3806446537, i64 1145181785, i64 168956806, i64 3641502830, i64 3584813610, i64 1689216846, i64 3666258015, i64 3200248200, i64 1692713982, i64 2646376535, i64 4042768518, i64 1618508792, i64 1610833997, i64 3523052358, i64 4130873264, i64 2001055236, i64 3610705100, i64 2202168115, i64 4028541809, i64 2961195399, i64 1006657119, i64 2006996926, i64 3186142756, i64 1430667929, i64 3210227297, i64 1314452623, i64 4074634658, i64 4101304120, i64 2273951170, i64 1399257539, i64 3367210612, i64 3027628629, i64 1190975929, i64 2062231137, i64 2333990788, i64 2221543033, i64 2438960610, i64 1181637006, i64 548689776, i64 2362791313, i64 3372408396, i64 3104550113, i64 3145860560, i64 296247880, i64 1970579870, i64 3078560182, i64 3769228297, i64 1714227617, i64 3291629107, i64 3898220290, i64 166772364, i64 1251581989, i64 493813264, i64 448347421, i64 195405023, i64 2709975567, i64 677966185, i64 3703036547, i64 1463355134, i64 2715995803, i64 1338867538, i64 1343315457, i64 2802222074, i64 2684532164, i64 233230375, i64 2599980071, i64 2000651841, i64 3277868038, i64 1638401717, i64 4028070440, i64 3237316320, i64 6314154, i64 819756386, i64 300326615, i64 590932579, i64 1405279636, i64 3267499572, i64 3150704214, i64 2428286686, i64 3959192993, i64 3461946742, i64 1862657033, i64 1266418056, i64 963775037, i64 2089974820, i64 2263052895, i64 1917689273, i64 448879540, i64 3550394620, i64 3981727096, i64 150775221, i64 3627908307, i64 1303187396, i64 508620638, i64 2975983352, i64 2726630617, i64 1817252668, i64 1876281319, i64 1457606340, i64 908771278, i64 3720792119, i64 3617206836, i64 2455994898, i64 1729034894, i64 1080033504, i64 976866871, i64 3556439503, i64 2881648439, i64 1522871579, i64 1555064734, i64 1336096578, i64 3548522304, i64 2579274686, i64 3574697629, i64 3205460757, i64 3593280638, i64 3338716283, i64 3079412587, i64 564236357, i64 2993598910, i64 1781952180, i64 1464380207, i64 3163844217, i64 3332601554, i64 1699332808, i64 1393555694, i64 1183702653, i64 3581086237, i64 1288719814, i64 691649499, i64 2847557200, i64 2895455976, i64 3193889540, i64 2717570544, i64 1781354906, i64 1676643554, i64 2592534050, i64 3230253752, i64 1126444790, i64 2770207658, i64 2633158820, i64 2210423226, i64 2615765581, i64 2414155088, i64 3127139286, i64 673620729, i64 2805611233, i64 1269405062, i64 4015350505, i64 3341807571, i64 4149409754, i64 1057255273, i64 2012875353, i64 2162469141, i64 2276492801, i64 2601117357, i64 993977747, i64 3918593370, i64 2654263191, i64 753973209, i64 36408145, i64 2530585658, i64 25011837, i64 3520020182, i64 2088578344, i64 530523599, i64 2918365339, i64 1524020338, i64 1518925132, i64 3760827505, i64 3759777254, i64 1202760957, i64 3985898139, i64 3906192525, i64 674977740, i64 4174734889, i64 2031300136, i64 2019492241, i64 3983892565, i64 4153806404, i64 3822280332, i64 352677332, i64 2297720250, i64 60907813, i64 90501309, i64 3286998549, i64 1016092578, i64 2535922412, i64 2839152426, i64 457141659, i64 509813237, i64 4120667899, i64 652014361, i64 1966332200, i64 2975202805, i64 55981186, i64 2327461051, i64 676427537, i64 3255491064, i64 2882294119, i64 3433927263, i64 1307055953, i64 942726286, i64 933058658, i64 2468411793, i64 3933900994, i64 4215176142, i64 1361170020, i64 2001714738, i64 2830558078, i64 3274259782, i64 1222529897, i64 1679025792, i64 2729314320, i64 3714953764, i64 1770335741, i64 151462246, i64 3013232138, i64 1682292957, i64 1483529935, i64 471910574, i64 1539241949, i64 458788160, i64 3436315007, i64 1807016891, i64 3718408830, i64 978976581, i64 1043663428, i64 3165965781, i64 1927990952, i64 4200891579, i64 2372276910, i64 3208408903, i64 3533431907, i64 1412390302, i64 2931980059, i64 4132332400, i64 1947078029, i64 3881505623, i64 4168226417, i64 2941484381, i64 1077988104, i64 1320477388, i64 886195818, i64 18198404, i64 3786409000, i64 2509781533, i64 112762804, i64 3463356488, i64 1866414978, i64 891333506, i64 18488651, i64 661792760, i64 1628790961, i64 3885187036, i64 3141171499, i64 876946877, i64 2693282273, i64 1372485963, i64 791857591, i64 2686433993, i64 3759982718, i64 3167212022, i64 3472953795, i64 2716379847, i64 445679433, i64 3561995674, i64 3504004811, i64 3574258232, i64 54117162, i64 3331405415, i64 2381918588, i64 3769707343, i64 4154350007, i64 1140177722, i64 4074052095, i64 668550556, i64 3214352940, i64 367459370, i64 261225585, i64 2610173221, i64 4209349473, i64 3468074219, i64 3265815641, i64 314222801, i64 3066103646, i64 3808782860, i64 282218597, i64 3406013506, i64 3773591054, i64 379116347, i64 1285071038, i64 846784868, i64 2669647154, i64 3771962079, i64 3550491691, i64 2305946142, i64 453669953, i64 1268987020, i64 3317592352, i64 3279303384, i64 3744833421, i64 2610507566, i64 3859509063, i64 266596637, i64 3847019092, i64 517658769, i64 3462560207, i64 3443424879, i64 370717030, i64 4247526661, i64 2224018117, i64 4143653529, i64 4112773975, i64 2788324899, i64 2477274417, i64 1456262402, i64 2901442914, i64 1517677493, i64 1846949527, i64 2295493580, i64 3734397586, i64 2176403920, i64 1280348187, i64 1908823572, i64 3871786941, i64 846861322, i64 1172426758, i64 3287448474, i64 3383383037, i64 1655181056, i64 3139813346, i64 901632758, i64 1897031941, i64 2986607138, i64 3066810236, i64 3447102507, i64 1393639104, i64 373351379, i64 950779232, i64 625454576, i64 3124240540, i64 4148612726, i64 2007998917, i64 544563296, i64 2244738638, i64 2330496472, i64 2058025392, i64 1291430526, i64 424198748, i64 50039436, i64 29584100, i64 3605783033, i64 2429876329, i64 2791104160, i64 1057563949, i64 3255363231, i64 3075367218, i64 3463963227, i64 1469046755, i64 985887462], align 16
@key_P = common global [18 x i64] zeroinitializer, align 16
@key_S = common global [1024 x i64] zeroinitializer, align 16
@in_key = constant [5200 x i8] c"KurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworrybutknowthatKurtVonneguKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworrybutknowthatKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworrybutknowthatKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworryKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworrybutknowthatKurtVonneguKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworrybutknowthatKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworrybutknowthatKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherestofmyadvicehasnobasismorereliablethanmyownmeanderingexperienceIwilldispensethisadvicenowEnjoythepowerandbeautyofyouryouthOhnevermindYouwillnotunderstandthepowerandbeautyofyouryouthuntiltheyvefadedButtrustmein20yearsyoulllookbackatphotosofyourselfandrecallinawayyoucantgraspnowhowmuchpossibilitylaybeforeyouandhowfabulousyoureallylookedYouarenotasfatasyouimagineDontworryaboutthefutureOrworrybutknowthattsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefutureKurtVonnegutsCommencementAddressatMITLadiesandgentlemenoftheclassof97WearsunscreenIfIcouldofferyouonlyonetipforthefuturesunscreenwouldbeitThelongtermbenefitsofsunscreenhavebeenprovedbyscientistswhereastherest", align 16
@out_key = constant [5200 x i8] c"\05\8C\E517\F7\B3\16\EAt\C5ih\FA\1Ej\FD|)i\EF\FC\BD\EF\B6?\BB\8C\EF\FD\8E\D8\1A\89\AA\E14\F8\0D\ADM4\F9C\C2\F6\CF\05M\11\AA\18!H\FC\09\1C\07!\909}\FA\8F0W\CB\C1\CD\CB\CF\CA\D6\878\13L\FBdz\8D\87g\D2\ADOm\10\CC\9B\02\0C#z\F7B\D4\1E\B7\CF\8E\C9\FF1\E5\D18\D5\AB\E8\B5z>*K5\88\EA\03,\12\08\86\A0\C1\DE\5C\97]\EELC\BA\91\1D\B8\D6\AD\B21)\FB\80\B9\BF1p\DF\FCU\DB_Dh\D2\03\137\7FLJ\0C\B4\16|\FC.\AA7\007\CA\90\E8\B3\C8\C9\CE%\DB\C3bM\9A\9D\16'\A9BW\CC\96\19Q\D6\91\A3\9A\A6\DC\1A]*#\01\8F\B2\85\03\0B5\B8\08\8F\CF\E6+\BCG88\F1\E6~\B4e\86z\AB\D9\AD\DD8.\A6\F0\9F\1D\B5\E4w\F0\D0\0A\BC\A4\019J\0F\09\8AR\FB\95\F69\1CF\F3\A8\90\C2k\D5pg\BA\AF;\BB\FAZ\EFI\E6\85\AD\C3\5C\D3\8E\A3\E2\B8\EDs9\10\11+\BC\BA\85\A52\C3\13D$\99\B2\0F4U4{]}V$\8A5;\A1\A1\1A\B2\CB\E4\1B%\8CC\EC\07\B6XG\8B\E4\16\0F\93\DC\12\84o\0D\F9(\01o\05\8C&k\06\F9\E6\82G\B2Q'(\1C\D9\D8v\9F\E4\D0y\0A8i\0B\01\A7i@\D1,V\BF\ED\FEe\19~\A1%6\0CW\9C\96\9BE4p\EA\8F\95)\0F-\D3\A5\BD\A2\89\A6\BC\AF\80\E0 \99\80\BE\A9\82\7F\BF\EE\DF\92\9B\B1\8E\B0N\E54`\8Dw\DF$\0A\18\0F\F5\80\07\C4jd\1E ?\84X\85\FA\C3\89\22\5C\DB\14uQ\D8\B5t\F1N\83\B2\22\8A\CE\0A\903\D2lozt1\D5\98\E8\E4\14\F5z\D4\E1\AD\BE\98\15==\B3\ADGn&\07\C6\9D\99\CFW\11**\D7\12\D0Z\AC\9D\17.%\A6\DAA\19\88\ADU\95i6\14\DA\06A\B8\EF.&\9DD\F0\E4u\E0\13\99\03\22\E9/9gO\11\D0\DF\5C\1Eo\7F=\CD\D4\E8\05\CFk\9EQ\C0\87CK<vD3\1E\C8\B0\BB>\01d\AD?v\1Fl\8B\8A\F8\E9Q\F4$\F1\E7:\9A\C9n\09'V\E3I<=(P\C3\E0\BB7\9AHh\DA<\FD\F8\D8Z,\D5N\B1\94L\F49\AA\01\A6K\CE{\A6\CE\87\DD!\82\1A\94\94\E0u8K\972Z1\040\FF\93*\B7:L\83\10m\DEVU\86\FD\D1J\11\DC\EER\C8\8CY\D2u\AE\B4D\06\A3\09\F9\F93|\B65\06='\BE\0A(?\CF\5C\BD\1EE1\08\E9tyP\95\A9H\A4\CB\98G\C9\A9\90\CDS\0A\D6\D5\00\93 >[\A2\A4\A0\D3\C4\9F\A6\09I\DDOut\14gpP\93\E2\CD\19l\D2=\A3.9f\B9~\03\06\1Bv\8BqC>\04\F2X\98_\5C\8E\E9\8B\22\B1\F4\82\0C\04S\1D\A8\AB\0FFs\D8$\DAj\D5\5C\D7\D7+\9B\C8M\C6D%\FF\D7>\9A4\FB\C6\947\CFOc\F3\87+@\CC\B3j\90Nx^\E9\A0\C8\5C\BF2+\81\E5\A8\C20\83N\E4\A3\9D`\AF\CB\BD\CDQ\EER=TTo\D9\A3\07\12M\9C)\D1/\0A\FA:\EC\BB\F8\D4\83<4~\B4q\CF\87p\C0\BE\B1D\ABM\DB\FDi\0C\9D\DE \9F\5C\B9X\C0q'\12M\D7p\DFr\80f*\DB\0F\7F\17r\98}\FE\0C4N\F2J\82}\8A\12,\98\0C\ECu\C2S\C0\FFm\DF\ED\1F\CB\AA(\BCZ.\C4|\F3\99\7F\F7t\AEC\E9\C7\94oD<N\C4w\9F\DAUp\09\14F\A8M.\1A'\13\0A\AC\9F\87\0A~\19\85\CF\C1 \99}e3UNNL\91\BAf\F9N\B6\8A\E0\11\CF\15\CD2\8B\DF\05\C4N\FE\EFR\81\DE\16\92\F5\B2\CD\A9\A8\8A\93\18oE^q\BE\9DR\E9W\86\95\FD[\A1\80-\FEQKf\1A\9A\9FI\A3\C6\06\1BT\88\A5t\BE\EA\11\A0\00\EDx\96\FC{\AE\EE\88\1D\E2\D3\14Vhz\87\F1\11\E5\CFzB\89\A4\1A\01Zj\8F\B6E\A0\BA\0A\E79O\E2\D1\BA{R\E7\E4B\EF\D6h\C8a\01\E5f\80Mi6v:U$\EF\85#\04\D0\8D\13\B1\AClm\9E'CF0\AF\D4\B5K2\F8b^\A1|\F9\BB\9E\89N#\8EZ\82qy?%K]\AE\16tsi\D7\DD\93u(\8E&i+\9A\A9'P.6\06\99\8F\F8\C1n\E8M\8Ca\14z\FDRP\CD\F9\8C\A8\8E\02\DF\9B\80K\F8K\A8Fq\82\C4heo\B6&\FA7\18\9CI\AFN6\0A\02\8E\FD\CE\04\CB\B1\DF_\E7-\0C{y\ED\95\BF1]R\9DUU\96\22\F1\ECW\09\BC\AC\97_X\00`\E9\D7\82\F7\9D\0A\1E\99\F9\C6\9F\BC/P\AF\DB\AB7\AC\D6\E76X2WqT\0A#\AAz_\ACI\E0ab(\9A\87^\8Am3\BD\95\B04\9Dk\18\18\1D\A2S\14\E4\C5\A3\A3\EEn\A6\D5\84#\AA@\F2\9F,_\E0\F2\FEz\9E\B5\D6\D8\E0\03#t\E2\F6\13\F8\E7\9A\BDH!\1F\A9\22\CCcL\0A5~4\A8p\BB3\AD\0Af\AA\F7\12N\EA6\D3\A5pDUq\F8\A5Z_\14Iy(\EEs\1D\7F\DF\B3\FCMk)\E9w\EFK\D0=\BC\C9#\E6\D7\03\CB\8D|\D2\B4\FC\00\F4\94\BE`-\DA\EAx\8F\88\00?G\D7\09\E9\1B\E2\1D\FFp@\EC\A5A'j\22\22\FB\FC\BC \16\F8\96D\5C\09\073\CD\84\00\06\A3\93@`\A8\CF\EBm\8A\1D\0E\DEh\8Da\B7u\8E&\18\C06\CEh\02<\0EM\EA\B6)\10\C0\03\0B\D4h\E0/\1Bg\D5\A7\B7z>\82\B3z\EE!\DE]\CF\EEuiybgY?\84\A8 f\F4\F0\11\0B\A9N\A7\F7\FD\E2\AE\D5t}c\1Ah6&\FC\D0\87\B0]\0A\1Dc\D9\9B\C6)\F4*c\14\E9\D4\C1\AF\1B{x\BB\9B\A7\0EF\E1\CB\12\81;\B1\87\00\FD\04\7F\9F7W\D7\C2\D0\04\E9^-\82\D5\E7Z\CCcZ)\A6]\08\1A\10|\0E\1F\85\10\B8\80\D1\B2\F7\DF\D3\09~`\1AV+~\11z\0DZk\99\C1V&\13\D9uH\F1\B8\A4\8E\A4\A9\EC\E2r\A9\16\E6\A8q\80\03\A61^G-\A1 M\A4~\C5\E2\83\BC\B0r\7F\1F\A2\C8\A8k\83X>\F8H\83\E1q\92\BD\FCh\94\116<\BF\CE\A1qU\C9\1A\C9|\17\91\86\12\BB\8F#\F6Jt+%h\F7\FA/;\FB\93`\CD\CF\84\CAa\BC\A9\86\0F_\BA\1F\9C\B7\00\F1\83\86\00<\96\93;\11\9AI\F5\12<\B4\B5q\C7\8F`\A2\C5\F9@%\AE\D90\17}\8D\D5\E3\FA\8B\C2L\EA\16\B9\EErX\0B?\08X\DAQ1\1F\D6\D4='\BF\C7a?/^\FC\C5\02_\F32\97\FE5\F4\C49<0T\0EU\D2\A31\D6G\BF\9F\EF\A5B\9BU\F0\5CZ:x\12\CB\BCP&\BC\B1p\B0h\9F\D6\D31\5CzA\B08F \99E\0C\89\C7\9FF\F2\B4<t\EBdX\FAC\E1h\81I\9B\AAd{\F3/\11\0A\89\B8>\03\F34\F4\93v\B8\17\07\16D\CE)\A7\CB\A6\E2\D6\B3\F3\F9\16v\E0g88\06\F6/(k\C08\154\A6\DCg\DBT\D2\14\19V&\B1\9D\C0\A3C\AA`*w\CB\CD\8C\D8\EB\E4\8A*\B3}Ip\C7\B4&\9Fd\5C\90\9E\F0\B7\CE*\F0\CE\F6\B6@9If\A4\E5\8CY\DB\EAc\A9n|]\BB[\05\C5X)\01B\92\0E\82p\BE\1C\11y\D9q\1F\EB\CD\A4\C0e\F8\8219\EFW\06u\81v=\D5\DB0Eq\B72?\9A\E3g\81Cq\98\F7\B3Q\88\EA`\92]\8B\C3k\DA\96+\81\1FS9\AB\EA\0BZF\A8\00\D2\82=n\D7\FB\A1=\92s\9A\A1\AD\8AB\F6=\10PJvg\90\D8\DBp7\D50\F5\C9\F0M_\E7\D9\CC\CE4\E3\F7:\81e\E7'\B3\BBBrZ\C1E\CB\CA\FCb\82\92\A16I\AB\A9\C9\18}\11\E8\B9A\1B\D4\E1\8E`S\17\8D[\9A\A1R\FD\FA\9A2U\DD\1B\B5\A8s\F3\F9\18\E5\9A\88sn\16\D7\A6?\13\13\C9\BB;T\11\81p\92c\13\B0\CFw\0B\DD\D6\06\16\87\E1\91t=e\80V\DA\D2nb\13\C4u\F8\C6\0D\96m\1En4?\DC\AA\D6\E2b\97{\C4\E9\A5\C6\8EK\05\BC\F1\9F\228e==\D0\8C\B3\19\89\85~\B0\A6\18\CE\85=]\80\FF\D8a\073\FB0M\D0\8B\9E\BB\D8\D8\9F\0Ar\F3\1F\F8Q\A0w\BD\DFKO-\0D\87\C1\E5\F7\92\F1r?A\22g`\C5\05\0F\E4-\D0\C8\C9\95J.c\B6\C9\8F\B8,\9E;75\0A\F9w\08\EF\AE\F4\A8\0F\96A\B6\BA2\09\C5\B0\F0\F3\B1\B5R\FB\0C#\F4\17\9E>\98+\ED3\D3\1D\CFZ\9C\0BP\C7\C1t\E6\97\98\FD\F4V\9B\08\F6\B8c+@\C4][\A9\05\ED\02:\D0Y\E1\CE\1F\1C\91 J0\133\C6\B7\EF4\D8\BC\98]n\8C-\921\1F\ACu2\08D\CC\03\DBu(\C3\E8\B3\C8\BAx7\01b\A8xp\B6\DA\DEMq\FF\BD\00\91XH\C7W\CCi.\BCMM\B7\15V2\D9\C3\0A\D7\1D\AE\9B>\DBH\7F\B5P\B3\B1\AF8\D5A<c\B17\0D\CD\F6#\CAg\D7qm\B9W\B9Z\01JX\95\BB\E6Q\03\87\AAIFqv\B7\FA\D1\D0\F8\11\C4$\BC\80\B91\86\96m\C3\0E\C1\8E+\05u\94\0F,\92\91\A2|\CA\EF}\CD\82\BD\DD\FD\ABI$\7F#\0C\E6\99\9F%\E3R\BC\E2l\B6\82=m~\8E\FE\F3+X\AC\1E\C1x\98\90\FC(\1F\13\B5v\1BC\A7\FE\F2bW\C0\16\AD\AD\81\09pvZ\8E\AF)P\C6\17\11S\C5\A3\FC\04z\F9}G\1BWG\19\ED\83\90\BD\F4\8C\DE\0B_\88\A6pX\04\1B\FA\07\DD\9Fv\22\B5p\0B@\DE_G\7F\D2Y\0BI\7F\D9\D7\FA\87\DF\E0\9B\1C\D2\AA\7F-|\94\9B|\83?z\85\15/\93$\BD\B0\91I\08\1F\C5\8A+\A0\A3.H0\1A8\AB\8A4\16\B7\BF\EAk\E6\CAW\FFl\AC\84\A4\9A\88\C8U\83\04\BCj\01\D5*1\DDF\DEpcGi\CE\0Dg\DF%h$a\FD\95\DEQ\E8\E9\E4\DF\88{\C9\0A3\AFP\A8\C6\EE(\A1q\AA.\90\C2\DA\98P\02\E4\DDD\BF[Q\15\D8D\9Cu\91Xo\F1\C9!\9E#\F5E\8C\A2+l.wE\E0y\88M<v\DB\97\93O\A1\EA\C1.\D8\DF\F1\EB\0F\E3\1BG\EA\EB\A3\8F\82j\F4\CA\17\DE\B94m\96+QD\DA\A2\AFL\A5\85\E8\ACh\F0\E2\86\10\BA\CA<*[\D1\80\04\FF~\9C\8E\F0\8F\E0\F0\06c?\D7JG9\12\19E\93V\9C\FC\9D\E3\AB\9D\10aeMF\DA\D42D\97k\AD\8C\DD\BA\D9'&\17\D9K\FBI\B2\06\E2\09\BB\E4K\C6]\BF\B4\1A\1D=\D7\87\00\ECA,,\B2\18\02b\5C\97\FAD-\C4\B2\AE_9\D9Xm\A3\EDa\CA\92\E7'\C5\1B\F2o\BF\0B\D1\02\9D\04\1A5\93\FA\8EB\CDM\E6T\956=\14\D4@?\F1c\EC\BAx\1C.\D1{\FEVb\00\8A\BF\02\B6\FA\B3B\DF\C1\80\FF\0Fc\04\0A\B2\85\9D\0E \CB*\DD\A0\07\B2/L\8B\83l\FCX\90)\13\DB\A8\D1\F8\C1\81W\B2y8\84Q$_\1E^\F2M\E0s;\D0\8E\AFk\C7\C0f\94\1A$\A7\D5li\B9c\B4d\AC\A3\EF\F8\E86\A9\B6\FC\86TpB\1A\1AS\8F\A2\C6\D6\02\EE\89\C3\A5\11#\DD\08e <T\8A\8Ef\F1#\FE\A8\BEn>:0\E4i\DB:\9F\B0\A2\E2 U\DA}|\DD'\AF;\F7n\B6\82\1EJ\10\8D\E8q\CB\8D\EA*Z\FB8]\01\9B\FF\04=C\10-\E9\C3J\0E\94v\F7\E0\AA\8D\E2S\BE\D1Z4\E1x\C9\EEL\CD\0C8*Tz^\EC\18|\87\A2\D8\90\05\E7l\A0!\C4c\02\FD\AF9;\05\05\E5\16\F1&|\B8AR`\D3\91\0F\1C\7F\90\E7\ACo\B8\FBG\D6\90`x\8D\80VaT\8A|\AA\A3\13\0B\B6\B6m\FEw\E9Io\94\09L\B4v\14\1D\BA\03\EF\F5\B3{\83\0F\CB\D7@:g\8D\1D\01\CE\B6\A8\D3v\98\F6Ds\A0'\0F\22\89\AE\AA\8Bv\CD\12\A6\E4T\8EY\B1\C9\0D\A3D\B3\DC?\BAd\1A\CD\93\F1}\BCr\A6\A8\D6e\94@\FF \D5\02'36bI\BDq\0EiV\E0i\B125\89\AD\99q\D7\06p\81q\FEbJw\0F\F7r\ED\A5\86\F7\E3t\B5Y\BD,R\07\C5\8C\9A{\9De\939\A2\8F\F8\8F\82i\9A\F5\C6m&\8B\CE\FF\AA?!\84x\E1\D5\1D\BA\A8\CC|\EF\C4\87\18\06e\D6>*\EF-\1D\F9\BA\A8tT6\82b\AAt\80r\A3\13\D3\1C\8E\07i\98\BC\11)\09(\1F\89Ebc\D1P\1E\D2\1Fp\93\DFjAJf\10i \D1s\B7F.\FDO\BA\1B\115\919\10\12\F9\15\AA\09n\BFs\22Gw\BD\16\9A\E7\9A\F8\0B\E4G\C6\0F\1A\E0&\19\A9L\A42\AA\B9p\BA\83\D4\BF\01 \A8\5C\14\E7@\A7\C1\BF\B0>Y\B6\8E\17\03S\0FyJ\B1t\5CX\AF\ECE\FD\10\1D\DF\C5\8Ax\9A\B9\DD0\85~\1B\ED\80g\94\D2\83_k\17.8\A7\91\BEEV\BC\F7_\AD\BB#+\A3\B4\C9\D1\C0\D1\91R+\FCR\17\0D\B6\A5\D2\C2\5Ct\FAdC\9F\84\95d\89T\1C\CFi\0D=.}\09qk\C2\C0\91\D7\B4F\1B\19\E8\DC\8F\1D@\BC\D0\0B\05\D9\C3_\0B\E2c\E2\CAuk\8D7/n\B9\C6\D6\94\B1\D1\96s\13\C9\CD\AD\F0~\AE\8B\D5\D7\04\14](l\B8\FCdu6x\7FG\A4\FC\F8I\86+2\DFH\8B\92\B9q%\AD\A2\8C\D2$\C5\10\9Ft\92\D4a\81\F8\FC\89\94`\82l\CF){\CF\F7c\FD\AE\0D\AC\D6\BA\C2\CF\FF\A0\92\C5\FA\DAn\C1\13~LcXm2\85\BB\CEt\0F\D1|Q\BCX\1C\EF\F1DG\1E}\82\1E\A3m\9C\8Cp\EE](\D0\08\E4\A1\E3\FF\BD\AF\05\C4\ED\B5ewS\BA\89\D4q\831\9Bzs\9F6\0Fv\09V\C2\CD\8C!\03\02\08\D1\1F\A0\05\1A\1D\B3\FC\99\D2\5C\F2S\16`M={\E4vCO\02\18\E8\06\D42\D6\B8/\18K\DA\A0\BE\84*\BEU\B2\E6F\D1S(\96\B0\86|_@\EA\A3\D4`\C7N\C7\AD\1A#\1BvI\91\B8\8B+#L\93\B1\A2^\E5b\AB\0E.\D0\06pA\AE\E5\801\1D\C9K0\D7\89\BC\EC\0D\D4\15w\FD\BCNoy\B2\02Z\C9:\F7]\B7\10\8A\EE\CA.M(\1C\BA~\E5\D9\C6\BE\A6v4d\EB_\D7\98<\16{\EB\D00\C3\7F\D8\BDb\8A\AA\F4\DEy\CB\CC\A5\11i1[\B8y\9E3\95\9C\C7\1C\A0\A2\07\CB<{\F0\97\F72\E0\DE\86\CDsHl\01.\1B|\B2\AF\DE\13{A5MXR\C1\F1\0Ae\83\CFvnq1\11\AAv\01\0Fc\C3\D2\ED\B5\E64;\B1s;\EB\D19\80\C8\DE\08o\07M\F4\09m\FB\EC~\E1\13`[Yb'\E0\ADF\8FDi\B1\FD\0C\5COX\CE$\83d\BBS\DF\A2\ABT\1DE\E8o\F0%\04\8Eu1V\CC\D9$:$\0En\DD\10\19\BB\F3\1DE\13M+\0AQ#\E5\E58\F7C\81d\D2\94)\EF\E9G\8A\BF\03J\0F\9F\DF<\C9\D2\9FK\1E\D8\83\B1\AB?\F3\BD'\9C\FFs\B5\F0\09\D8\B8\E4\CB\87\F2ll\A7\122\AB\17\8B\95\E8)\B8&\D8\E8g2t\92\8D\BB\CC<\F9\8C\0D\0Di\8Cq\B8y\EA\C7 \AB\13\F6\C0c\C26\A0_\B1c\5C\B4\9DT\0A\7F\8D\FC>;\8BT\9BM\D4\0E[\B0\A3\D8\02\9C\E4\E9!\96\DF\B5\C2`2.M\A0\EE\A6#\00\B4\08~\0F^\08\0A&_U\85\A3\97\13\FD\22g*z\D6\DD-\8A\D5\A0\CF^v!\81\C0\16\A1\B7\D3\C0\8D\CE\C5\8D.\FE|K\E8\1A\AFM\B8\EE\1AY\8Dv\8BI\B5q\E1\F9\84l\08\09\CF\99L\E9\155\A9\D9e\86\E3\D7\C7\E5W\1F\EA'\11\88\C4Z\0EM\FD\D0\13\E5+\FE\02qSFL''G\87\01\B2\8F[\CD\1CfW\E2FK\AEK\A3~V>A\87\8B\84\86>\5C\BA\00\03W\FDm\A68\BA|\E01\AB \EF.\A3i\A8\F3\8Eod\CF\D0\08p^\91\1E\19q\E1E\E9\DF\F2!\C5\CC\03T3\BDX\99X=\87\16\E2\B1\DE\95F\A6\C7'g\AF\C6\12\B7w\5CU5\AAita\D3G\CF\05k\F5\9A\D4\03\86\CE+z\E0\C3\1A\BD\1A\D7\B3\C7\12\FC\B2e\B9\C2\A9\9B\B1\88\D3\B4\EAX\E0\17\DB\AF2#J\F1\93l\7Fn\D3\F1\9F\D0\E9\C2\A9\05t\9B\A0z\90b\C8\D71\09\83\8C|\9BR\DE\E7\E0\CBAs^\C8q\8C\C0}#\A7\83\98\9EA\C19Q\AC\E8-\B8A:\0C\D3j\E3\FDN\AFT\D0\F3qd@i'\F5\DFs\FCjO\C0\A6\19\95\8D\F0\D7\BD\B7\C1J\BFsPb\19\B6\01\A4\9C\0B\13Gm\D9m\FF\01\D8\F1\95qJZ+\0A\C8\E7(I\E7G\CE\7F\F3\9F\BA\AB9t\09Z\102\AA\07\05P<\80JD\B2b\F6p\BAH\E2\B7\C0\049\1E\DD1\CB\ED\03%\FD/\C7\CA(8e\B1\96\D3\97\A5g\EB\D3\D1\890\03.\06\C6$\A7\FB\BEI\D6\08\D0\F9\05\07\F5\A9\C3\E6tl\81\B47m\CB|\0B\B3-\A86\146\E6\FD\7F\C3z\EC\AF\A4\CD\F5M\C3r\0B\C3\8F\F5{\E8\F1\5C\D5\C7\1B\AA\E6 B\AF\7FZ\93\01\E9L\14\E5V~\A7\BF\D8uU\F8\BC\D6\E9\8BU\C2\08\D6\9D\EB\A8\B2#\C0\B1|\8CF\D4vtz\ED\14i\E5\0E\B1\E7\C9c\8Cah\1A\E2C\E9\19\B04P\88\DC\90\CC\C0h\00\98S\AF\FF{(t\14\BFOD=\E0\D4L\D6\BE\EAWB\E03\BBf(0\9Bj\D8i\D4m\E9rx\E1\9D\82\0D:,o\DF\D3ElA\11\D5\BCK\C5\F2(J!b\09\12\CC\C1zd\CE\CC\BD\F3\ADGn\E6\F3g\A5c\12W\D1\B7\22\C3\02\C7\C1\B6\97\92k\CA\A6\DEO\C4\8DY\C5\FE\B8\104\03\D8\095M\1D\DE\80\94+u+\A6;\99\CF\99Z\D3x\FFn[b\82\AB\95\5C+\B3+\1A\B9\0F\07\10]oU\A2 \8F\0E\00\AD\01F\C5\D8\AA\E7\8E\AE\EE\D1 \16\E4\D0'b\0F2\0DE\DC\A9\D0D@e\D1u\AF]\D4\FDIK\F9\015\B4^{R\A8 A\8A\88\FCZB\C1\B9<\F8\AC\A1\E4\80\82nv\5C\C693SR\F0At\94\DF\CE\94|m6\CA\1C\A9\CAd\1B\EB\ED12\BCHX\BAa(\12Q\9Dxm\C1.\03P5\B6\1F\D6\A5 \97^\04qN\DC\CD$\85\ED\97\012\A0?\D2AT\94X!\0E\D0\5C\AEu\A4\B5\C5\9B\EE\90\F6\1A\0C\D0<:_yi\85\1D@\18)\DD\B8'M\A9q\8B\A0%\E8dS\B8\D1\0450\EB>g\F7\158<m\9AL\06]^E\13K\CCA\09\DFt\FB\F5r\15\F4\F7.\98=\D7i\F7-=\0Bs\A3\117\CE6\0F\ADs\7F\0C\02>\E3\A0\03*\FD7\A5\95\02\E7\86yBO\19{\D9\8B\ADW\E8\E8^\94\A9\A6 $\9E\CB\8D\91\1A|\B2T\EF\17\CCh\C6\BA\90\97Q\97\EC\82\F9HUgm\B7x\95->Z\EE\91\22m\D1~\81\CF\81L\5C\B8:yk1'J\A0\D2#", align 16
@.str = private unnamed_addr constant [10 x i8] c"Time: %f\0A\00", align 1
@.str.1 = private unnamed_addr constant [12 x i8] c"Result: %d\0A\00", align 1

; Function Attrs: noinline nounwind ssp uwtable
define void @local_memcpy(i64* %s1, i64* %s2, i32 %n) #0 {
entry:
  %s1.addr = alloca i64*, align 8
  %s2.addr = alloca i64*, align 8
  %n.addr = alloca i32, align 4
  %p1 = alloca i64*, align 8
  %p2 = alloca i64*, align 8
  store i64* %s1, i64** %s1.addr, align 8
  store i64* %s2, i64** %s2.addr, align 8
  store i32 %n, i32* %n.addr, align 4
  %0 = load i64*, i64** %s1.addr, align 8
  store i64* %0, i64** %p1, align 8
  %1 = load i64*, i64** %s2.addr, align 8
  store i64* %1, i64** %p2, align 8
  br label %while.cond

while.cond:                                       ; preds = %while.body, %entry
  %2 = load i32, i32* %n.addr, align 4
  %dec = add nsw i32 %2, -1
  store i32 %dec, i32* %n.addr, align 4
  %cmp = icmp sgt i32 %2, 0
  br i1 %cmp, label %while.body, label %while.end

while.body:                                       ; preds = %while.cond
  %3 = load i64*, i64** %p2, align 8
  %4 = load i64, i64* %3, align 8
  %5 = load i64*, i64** %p1, align 8
  store i64 %4, i64* %5, align 8
  %6 = load i64*, i64** %p1, align 8
  %incdec.ptr = getelementptr inbounds i64, i64* %6, i32 1
  store i64* %incdec.ptr, i64** %p1, align 8
  %7 = load i64*, i64** %p2, align 8
  %incdec.ptr1 = getelementptr inbounds i64, i64* %7, i32 1
  store i64* %incdec.ptr1, i64** %p2, align 8
  br label %while.cond

while.end:                                        ; preds = %while.cond
  ret void
}

; Function Attrs: noinline nounwind ssp uwtable
define void @BF_set_key(i32 %len, i8* %data) #0 {
entry:
  %len.addr = alloca i32, align 4
  %data.addr = alloca i8*, align 8
  %i = alloca i32, align 4
  %p = alloca i64*, align 8
  %ri = alloca i64, align 8
  %in = alloca [2 x i64], align 16
  %d = alloca i8*, align 8
  %end = alloca i8*, align 8
  store i32 %len, i32* %len.addr, align 4
  store i8* %data, i8** %data.addr, align 8
  call void @local_memcpy(i64* getelementptr inbounds ([18 x i64], [18 x i64]* @key_P, i32 0, i32 0), i64* getelementptr inbounds ([18 x i64], [18 x i64]* @bf_init_P, i32 0, i32 0), i32 18)
  call void @local_memcpy(i64* getelementptr inbounds ([1024 x i64], [1024 x i64]* @key_S, i32 0, i32 0), i64* getelementptr inbounds ([1024 x i64], [1024 x i64]* @bf_init_S, i32 0, i32 0), i32 1024)
  store i64* getelementptr inbounds ([18 x i64], [18 x i64]* @key_P, i32 0, i32 0), i64** %p, align 8
  %0 = load i32, i32* %len.addr, align 4
  %cmp = icmp sgt i32 %0, 72
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %entry
  store i32 72, i32* %len.addr, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %entry
  %1 = load i8*, i8** %data.addr, align 8
  store i8* %1, i8** %d, align 8
  %2 = load i8*, i8** %data.addr, align 8
  %3 = load i32, i32* %len.addr, align 4
  %idxprom = sext i32 %3 to i64
  %arrayidx = getelementptr inbounds i8, i8* %2, i64 %idxprom
  store i8* %arrayidx, i8** %end, align 8
  store i32 0, i32* %i, align 4
  br label %for.cond

for.cond:                                         ; preds = %for.inc, %if.end
  %4 = load i32, i32* %i, align 4
  %cmp1 = icmp slt i32 %4, 18
  br i1 %cmp1, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %5 = load i8*, i8** %d, align 8
  %incdec.ptr = getelementptr inbounds i8, i8* %5, i32 1
  store i8* %incdec.ptr, i8** %d, align 8
  %6 = load i8, i8* %5, align 1
  %conv = zext i8 %6 to i64
  store i64 %conv, i64* %ri, align 8
  %7 = load i8*, i8** %d, align 8
  %8 = load i8*, i8** %end, align 8
  %cmp2 = icmp uge i8* %7, %8
  br i1 %cmp2, label %if.then4, label %if.end5

if.then4:                                         ; preds = %for.body
  %9 = load i8*, i8** %data.addr, align 8
  store i8* %9, i8** %d, align 8
  br label %if.end5

if.end5:                                          ; preds = %if.then4, %for.body
  %10 = load i64, i64* %ri, align 8
  %shl = shl i64 %10, 8
  store i64 %shl, i64* %ri, align 8
  %11 = load i8*, i8** %d, align 8
  %incdec.ptr6 = getelementptr inbounds i8, i8* %11, i32 1
  store i8* %incdec.ptr6, i8** %d, align 8
  %12 = load i8, i8* %11, align 1
  %conv7 = zext i8 %12 to i64
  %13 = load i64, i64* %ri, align 8
  %or = or i64 %13, %conv7
  store i64 %or, i64* %ri, align 8
  %14 = load i8*, i8** %d, align 8
  %15 = load i8*, i8** %end, align 8
  %cmp8 = icmp uge i8* %14, %15
  br i1 %cmp8, label %if.then10, label %if.end11

if.then10:                                        ; preds = %if.end5
  %16 = load i8*, i8** %data.addr, align 8
  store i8* %16, i8** %d, align 8
  br label %if.end11

if.end11:                                         ; preds = %if.then10, %if.end5
  %17 = load i64, i64* %ri, align 8
  %shl12 = shl i64 %17, 8
  store i64 %shl12, i64* %ri, align 8
  %18 = load i8*, i8** %d, align 8
  %incdec.ptr13 = getelementptr inbounds i8, i8* %18, i32 1
  store i8* %incdec.ptr13, i8** %d, align 8
  %19 = load i8, i8* %18, align 1
  %conv14 = zext i8 %19 to i64
  %20 = load i64, i64* %ri, align 8
  %or15 = or i64 %20, %conv14
  store i64 %or15, i64* %ri, align 8
  %21 = load i8*, i8** %d, align 8
  %22 = load i8*, i8** %end, align 8
  %cmp16 = icmp uge i8* %21, %22
  br i1 %cmp16, label %if.then18, label %if.end19

if.then18:                                        ; preds = %if.end11
  %23 = load i8*, i8** %data.addr, align 8
  store i8* %23, i8** %d, align 8
  br label %if.end19

if.end19:                                         ; preds = %if.then18, %if.end11
  %24 = load i64, i64* %ri, align 8
  %shl20 = shl i64 %24, 8
  store i64 %shl20, i64* %ri, align 8
  %25 = load i8*, i8** %d, align 8
  %incdec.ptr21 = getelementptr inbounds i8, i8* %25, i32 1
  store i8* %incdec.ptr21, i8** %d, align 8
  %26 = load i8, i8* %25, align 1
  %conv22 = zext i8 %26 to i64
  %27 = load i64, i64* %ri, align 8
  %or23 = or i64 %27, %conv22
  store i64 %or23, i64* %ri, align 8
  %28 = load i8*, i8** %d, align 8
  %29 = load i8*, i8** %end, align 8
  %cmp24 = icmp uge i8* %28, %29
  br i1 %cmp24, label %if.then26, label %if.end27

if.then26:                                        ; preds = %if.end19
  %30 = load i8*, i8** %data.addr, align 8
  store i8* %30, i8** %d, align 8
  br label %if.end27

if.end27:                                         ; preds = %if.then26, %if.end19
  %31 = load i64, i64* %ri, align 8
  %32 = load i64*, i64** %p, align 8
  %33 = load i32, i32* %i, align 4
  %idxprom28 = sext i32 %33 to i64
  %arrayidx29 = getelementptr inbounds i64, i64* %32, i64 %idxprom28
  %34 = load i64, i64* %arrayidx29, align 8
  %xor = xor i64 %34, %31
  store i64 %xor, i64* %arrayidx29, align 8
  br label %for.inc

for.inc:                                          ; preds = %if.end27
  %35 = load i32, i32* %i, align 4
  %inc = add nsw i32 %35, 1
  store i32 %inc, i32* %i, align 4
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %arrayidx30 = getelementptr inbounds [2 x i64], [2 x i64]* %in, i64 0, i64 0
  store i64 0, i64* %arrayidx30, align 16
  %arrayidx31 = getelementptr inbounds [2 x i64], [2 x i64]* %in, i64 0, i64 1
  store i64 0, i64* %arrayidx31, align 8
  store i32 0, i32* %i, align 4
  br label %for.cond32

for.cond32:                                       ; preds = %for.inc42, %for.end
  %36 = load i32, i32* %i, align 4
  %cmp33 = icmp slt i32 %36, 18
  br i1 %cmp33, label %for.body35, label %for.end44

for.body35:                                       ; preds = %for.cond32
  %arraydecay = getelementptr inbounds [2 x i64], [2 x i64]* %in, i32 0, i32 0
  call void @BF_encrypt(i64* %arraydecay, i32 1)
  %arrayidx36 = getelementptr inbounds [2 x i64], [2 x i64]* %in, i64 0, i64 0
  %37 = load i64, i64* %arrayidx36, align 16
  %38 = load i64*, i64** %p, align 8
  %39 = load i32, i32* %i, align 4
  %idxprom37 = sext i32 %39 to i64
  %arrayidx38 = getelementptr inbounds i64, i64* %38, i64 %idxprom37
  store i64 %37, i64* %arrayidx38, align 8
  %arrayidx39 = getelementptr inbounds [2 x i64], [2 x i64]* %in, i64 0, i64 1
  %40 = load i64, i64* %arrayidx39, align 8
  %41 = load i64*, i64** %p, align 8
  %42 = load i32, i32* %i, align 4
  %add = add nsw i32 %42, 1
  %idxprom40 = sext i32 %add to i64
  %arrayidx41 = getelementptr inbounds i64, i64* %41, i64 %idxprom40
  store i64 %40, i64* %arrayidx41, align 8
  br label %for.inc42

for.inc42:                                        ; preds = %for.body35
  %43 = load i32, i32* %i, align 4
  %add43 = add nsw i32 %43, 2
  store i32 %add43, i32* %i, align 4
  br label %for.cond32

for.end44:                                        ; preds = %for.cond32
  store i64* getelementptr inbounds ([1024 x i64], [1024 x i64]* @key_S, i32 0, i32 0), i64** %p, align 8
  store i32 0, i32* %i, align 4
  br label %for.cond45

for.cond45:                                       ; preds = %for.inc57, %for.end44
  %44 = load i32, i32* %i, align 4
  %cmp46 = icmp slt i32 %44, 1024
  br i1 %cmp46, label %for.body48, label %for.end59

for.body48:                                       ; preds = %for.cond45
  %arraydecay49 = getelementptr inbounds [2 x i64], [2 x i64]* %in, i32 0, i32 0
  call void @BF_encrypt(i64* %arraydecay49, i32 1)
  %arrayidx50 = getelementptr inbounds [2 x i64], [2 x i64]* %in, i64 0, i64 0
  %45 = load i64, i64* %arrayidx50, align 16
  %46 = load i64*, i64** %p, align 8
  %47 = load i32, i32* %i, align 4
  %idxprom51 = sext i32 %47 to i64
  %arrayidx52 = getelementptr inbounds i64, i64* %46, i64 %idxprom51
  store i64 %45, i64* %arrayidx52, align 8
  %arrayidx53 = getelementptr inbounds [2 x i64], [2 x i64]* %in, i64 0, i64 1
  %48 = load i64, i64* %arrayidx53, align 8
  %49 = load i64*, i64** %p, align 8
  %50 = load i32, i32* %i, align 4
  %add54 = add nsw i32 %50, 1
  %idxprom55 = sext i32 %add54 to i64
  %arrayidx56 = getelementptr inbounds i64, i64* %49, i64 %idxprom55
  store i64 %48, i64* %arrayidx56, align 8
  br label %for.inc57

for.inc57:                                        ; preds = %for.body48
  %51 = load i32, i32* %i, align 4
  %add58 = add nsw i32 %51, 2
  store i32 %add58, i32* %i, align 4
  br label %for.cond45

for.end59:                                        ; preds = %for.cond45
  ret void
}

; Function Attrs: noinline nounwind ssp uwtable
define void @BF_encrypt(i64* %data, i32 %encrypt) #0 {
entry:
  %data.addr = alloca i64*, align 8
  %encrypt.addr = alloca i32, align 4
  %l = alloca i64, align 8
  %r = alloca i64, align 8
  %p = alloca i64*, align 8
  %s = alloca i64*, align 8
  store i64* %data, i64** %data.addr, align 8
  store i32 %encrypt, i32* %encrypt.addr, align 4
  store i64* getelementptr inbounds ([18 x i64], [18 x i64]* @key_P, i32 0, i32 0), i64** %p, align 8
  store i64* getelementptr inbounds ([1024 x i64], [1024 x i64]* @key_S, i64 0, i64 0), i64** %s, align 8
  %0 = load i64*, i64** %data.addr, align 8
  %arrayidx = getelementptr inbounds i64, i64* %0, i64 0
  %1 = load i64, i64* %arrayidx, align 8
  store i64 %1, i64* %l, align 8
  %2 = load i64*, i64** %data.addr, align 8
  %arrayidx1 = getelementptr inbounds i64, i64* %2, i64 1
  %3 = load i64, i64* %arrayidx1, align 8
  store i64 %3, i64* %r, align 8
  %4 = load i32, i32* %encrypt.addr, align 4
  %tobool = icmp ne i32 %4, 0
  br i1 %tobool, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  %5 = load i64*, i64** %p, align 8
  %arrayidx2 = getelementptr inbounds i64, i64* %5, i64 0
  %6 = load i64, i64* %arrayidx2, align 8
  %7 = load i64, i64* %l, align 8
  %xor = xor i64 %7, %6
  store i64 %xor, i64* %l, align 8
  %8 = load i64*, i64** %p, align 8
  %arrayidx3 = getelementptr inbounds i64, i64* %8, i64 1
  %9 = load i64, i64* %arrayidx3, align 8
  %10 = load i64, i64* %r, align 8
  %xor4 = xor i64 %10, %9
  store i64 %xor4, i64* %r, align 8
  %11 = load i64*, i64** %s, align 8
  %12 = load i64, i64* %l, align 8
  %shr = lshr i64 %12, 24
  %arrayidx5 = getelementptr inbounds i64, i64* %11, i64 %shr
  %13 = load i64, i64* %arrayidx5, align 8
  %14 = load i64*, i64** %s, align 8
  %15 = load i64, i64* %l, align 8
  %shr6 = lshr i64 %15, 16
  %and = and i64 %shr6, 255
  %add = add i64 256, %and
  %arrayidx7 = getelementptr inbounds i64, i64* %14, i64 %add
  %16 = load i64, i64* %arrayidx7, align 8
  %add8 = add i64 %13, %16
  %17 = load i64*, i64** %s, align 8
  %18 = load i64, i64* %l, align 8
  %shr9 = lshr i64 %18, 8
  %and10 = and i64 %shr9, 255
  %add11 = add i64 512, %and10
  %arrayidx12 = getelementptr inbounds i64, i64* %17, i64 %add11
  %19 = load i64, i64* %arrayidx12, align 8
  %xor13 = xor i64 %add8, %19
  %20 = load i64*, i64** %s, align 8
  %21 = load i64, i64* %l, align 8
  %and14 = and i64 %21, 255
  %add15 = add i64 768, %and14
  %arrayidx16 = getelementptr inbounds i64, i64* %20, i64 %add15
  %22 = load i64, i64* %arrayidx16, align 8
  %add17 = add i64 %xor13, %22
  %and18 = and i64 %add17, 4294967295
  %23 = load i64, i64* %r, align 8
  %xor19 = xor i64 %23, %and18
  store i64 %xor19, i64* %r, align 8
  %24 = load i64*, i64** %p, align 8
  %arrayidx20 = getelementptr inbounds i64, i64* %24, i64 2
  %25 = load i64, i64* %arrayidx20, align 8
  %26 = load i64, i64* %l, align 8
  %xor21 = xor i64 %26, %25
  store i64 %xor21, i64* %l, align 8
  %27 = load i64*, i64** %s, align 8
  %28 = load i64, i64* %r, align 8
  %shr22 = lshr i64 %28, 24
  %arrayidx23 = getelementptr inbounds i64, i64* %27, i64 %shr22
  %29 = load i64, i64* %arrayidx23, align 8
  %30 = load i64*, i64** %s, align 8
  %31 = load i64, i64* %r, align 8
  %shr24 = lshr i64 %31, 16
  %and25 = and i64 %shr24, 255
  %add26 = add i64 256, %and25
  %arrayidx27 = getelementptr inbounds i64, i64* %30, i64 %add26
  %32 = load i64, i64* %arrayidx27, align 8
  %add28 = add i64 %29, %32
  %33 = load i64*, i64** %s, align 8
  %34 = load i64, i64* %r, align 8
  %shr29 = lshr i64 %34, 8
  %and30 = and i64 %shr29, 255
  %add31 = add i64 512, %and30
  %arrayidx32 = getelementptr inbounds i64, i64* %33, i64 %add31
  %35 = load i64, i64* %arrayidx32, align 8
  %xor33 = xor i64 %add28, %35
  %36 = load i64*, i64** %s, align 8
  %37 = load i64, i64* %r, align 8
  %and34 = and i64 %37, 255
  %add35 = add i64 768, %and34
  %arrayidx36 = getelementptr inbounds i64, i64* %36, i64 %add35
  %38 = load i64, i64* %arrayidx36, align 8
  %add37 = add i64 %xor33, %38
  %and38 = and i64 %add37, 4294967295
  %39 = load i64, i64* %l, align 8
  %xor39 = xor i64 %39, %and38
  store i64 %xor39, i64* %l, align 8
  %40 = load i64*, i64** %p, align 8
  %arrayidx40 = getelementptr inbounds i64, i64* %40, i64 3
  %41 = load i64, i64* %arrayidx40, align 8
  %42 = load i64, i64* %r, align 8
  %xor41 = xor i64 %42, %41
  store i64 %xor41, i64* %r, align 8
  %43 = load i64*, i64** %s, align 8
  %44 = load i64, i64* %l, align 8
  %shr42 = lshr i64 %44, 24
  %arrayidx43 = getelementptr inbounds i64, i64* %43, i64 %shr42
  %45 = load i64, i64* %arrayidx43, align 8
  %46 = load i64*, i64** %s, align 8
  %47 = load i64, i64* %l, align 8
  %shr44 = lshr i64 %47, 16
  %and45 = and i64 %shr44, 255
  %add46 = add i64 256, %and45
  %arrayidx47 = getelementptr inbounds i64, i64* %46, i64 %add46
  %48 = load i64, i64* %arrayidx47, align 8
  %add48 = add i64 %45, %48
  %49 = load i64*, i64** %s, align 8
  %50 = load i64, i64* %l, align 8
  %shr49 = lshr i64 %50, 8
  %and50 = and i64 %shr49, 255
  %add51 = add i64 512, %and50
  %arrayidx52 = getelementptr inbounds i64, i64* %49, i64 %add51
  %51 = load i64, i64* %arrayidx52, align 8
  %xor53 = xor i64 %add48, %51
  %52 = load i64*, i64** %s, align 8
  %53 = load i64, i64* %l, align 8
  %and54 = and i64 %53, 255
  %add55 = add i64 768, %and54
  %arrayidx56 = getelementptr inbounds i64, i64* %52, i64 %add55
  %54 = load i64, i64* %arrayidx56, align 8
  %add57 = add i64 %xor53, %54
  %and58 = and i64 %add57, 4294967295
  %55 = load i64, i64* %r, align 8
  %xor59 = xor i64 %55, %and58
  store i64 %xor59, i64* %r, align 8
  %56 = load i64*, i64** %p, align 8
  %arrayidx60 = getelementptr inbounds i64, i64* %56, i64 4
  %57 = load i64, i64* %arrayidx60, align 8
  %58 = load i64, i64* %l, align 8
  %xor61 = xor i64 %58, %57
  store i64 %xor61, i64* %l, align 8
  %59 = load i64*, i64** %s, align 8
  %60 = load i64, i64* %r, align 8
  %shr62 = lshr i64 %60, 24
  %arrayidx63 = getelementptr inbounds i64, i64* %59, i64 %shr62
  %61 = load i64, i64* %arrayidx63, align 8
  %62 = load i64*, i64** %s, align 8
  %63 = load i64, i64* %r, align 8
  %shr64 = lshr i64 %63, 16
  %and65 = and i64 %shr64, 255
  %add66 = add i64 256, %and65
  %arrayidx67 = getelementptr inbounds i64, i64* %62, i64 %add66
  %64 = load i64, i64* %arrayidx67, align 8
  %add68 = add i64 %61, %64
  %65 = load i64*, i64** %s, align 8
  %66 = load i64, i64* %r, align 8
  %shr69 = lshr i64 %66, 8
  %and70 = and i64 %shr69, 255
  %add71 = add i64 512, %and70
  %arrayidx72 = getelementptr inbounds i64, i64* %65, i64 %add71
  %67 = load i64, i64* %arrayidx72, align 8
  %xor73 = xor i64 %add68, %67
  %68 = load i64*, i64** %s, align 8
  %69 = load i64, i64* %r, align 8
  %and74 = and i64 %69, 255
  %add75 = add i64 768, %and74
  %arrayidx76 = getelementptr inbounds i64, i64* %68, i64 %add75
  %70 = load i64, i64* %arrayidx76, align 8
  %add77 = add i64 %xor73, %70
  %and78 = and i64 %add77, 4294967295
  %71 = load i64, i64* %l, align 8
  %xor79 = xor i64 %71, %and78
  store i64 %xor79, i64* %l, align 8
  %72 = load i64*, i64** %p, align 8
  %arrayidx80 = getelementptr inbounds i64, i64* %72, i64 5
  %73 = load i64, i64* %arrayidx80, align 8
  %74 = load i64, i64* %r, align 8
  %xor81 = xor i64 %74, %73
  store i64 %xor81, i64* %r, align 8
  %75 = load i64*, i64** %s, align 8
  %76 = load i64, i64* %l, align 8
  %shr82 = lshr i64 %76, 24
  %arrayidx83 = getelementptr inbounds i64, i64* %75, i64 %shr82
  %77 = load i64, i64* %arrayidx83, align 8
  %78 = load i64*, i64** %s, align 8
  %79 = load i64, i64* %l, align 8
  %shr84 = lshr i64 %79, 16
  %and85 = and i64 %shr84, 255
  %add86 = add i64 256, %and85
  %arrayidx87 = getelementptr inbounds i64, i64* %78, i64 %add86
  %80 = load i64, i64* %arrayidx87, align 8
  %add88 = add i64 %77, %80
  %81 = load i64*, i64** %s, align 8
  %82 = load i64, i64* %l, align 8
  %shr89 = lshr i64 %82, 8
  %and90 = and i64 %shr89, 255
  %add91 = add i64 512, %and90
  %arrayidx92 = getelementptr inbounds i64, i64* %81, i64 %add91
  %83 = load i64, i64* %arrayidx92, align 8
  %xor93 = xor i64 %add88, %83
  %84 = load i64*, i64** %s, align 8
  %85 = load i64, i64* %l, align 8
  %and94 = and i64 %85, 255
  %add95 = add i64 768, %and94
  %arrayidx96 = getelementptr inbounds i64, i64* %84, i64 %add95
  %86 = load i64, i64* %arrayidx96, align 8
  %add97 = add i64 %xor93, %86
  %and98 = and i64 %add97, 4294967295
  %87 = load i64, i64* %r, align 8
  %xor99 = xor i64 %87, %and98
  store i64 %xor99, i64* %r, align 8
  %88 = load i64*, i64** %p, align 8
  %arrayidx100 = getelementptr inbounds i64, i64* %88, i64 6
  %89 = load i64, i64* %arrayidx100, align 8
  %90 = load i64, i64* %l, align 8
  %xor101 = xor i64 %90, %89
  store i64 %xor101, i64* %l, align 8
  %91 = load i64*, i64** %s, align 8
  %92 = load i64, i64* %r, align 8
  %shr102 = lshr i64 %92, 24
  %arrayidx103 = getelementptr inbounds i64, i64* %91, i64 %shr102
  %93 = load i64, i64* %arrayidx103, align 8
  %94 = load i64*, i64** %s, align 8
  %95 = load i64, i64* %r, align 8
  %shr104 = lshr i64 %95, 16
  %and105 = and i64 %shr104, 255
  %add106 = add i64 256, %and105
  %arrayidx107 = getelementptr inbounds i64, i64* %94, i64 %add106
  %96 = load i64, i64* %arrayidx107, align 8
  %add108 = add i64 %93, %96
  %97 = load i64*, i64** %s, align 8
  %98 = load i64, i64* %r, align 8
  %shr109 = lshr i64 %98, 8
  %and110 = and i64 %shr109, 255
  %add111 = add i64 512, %and110
  %arrayidx112 = getelementptr inbounds i64, i64* %97, i64 %add111
  %99 = load i64, i64* %arrayidx112, align 8
  %xor113 = xor i64 %add108, %99
  %100 = load i64*, i64** %s, align 8
  %101 = load i64, i64* %r, align 8
  %and114 = and i64 %101, 255
  %add115 = add i64 768, %and114
  %arrayidx116 = getelementptr inbounds i64, i64* %100, i64 %add115
  %102 = load i64, i64* %arrayidx116, align 8
  %add117 = add i64 %xor113, %102
  %and118 = and i64 %add117, 4294967295
  %103 = load i64, i64* %l, align 8
  %xor119 = xor i64 %103, %and118
  store i64 %xor119, i64* %l, align 8
  %104 = load i64*, i64** %p, align 8
  %arrayidx120 = getelementptr inbounds i64, i64* %104, i64 7
  %105 = load i64, i64* %arrayidx120, align 8
  %106 = load i64, i64* %r, align 8
  %xor121 = xor i64 %106, %105
  store i64 %xor121, i64* %r, align 8
  %107 = load i64*, i64** %s, align 8
  %108 = load i64, i64* %l, align 8
  %shr122 = lshr i64 %108, 24
  %arrayidx123 = getelementptr inbounds i64, i64* %107, i64 %shr122
  %109 = load i64, i64* %arrayidx123, align 8
  %110 = load i64*, i64** %s, align 8
  %111 = load i64, i64* %l, align 8
  %shr124 = lshr i64 %111, 16
  %and125 = and i64 %shr124, 255
  %add126 = add i64 256, %and125
  %arrayidx127 = getelementptr inbounds i64, i64* %110, i64 %add126
  %112 = load i64, i64* %arrayidx127, align 8
  %add128 = add i64 %109, %112
  %113 = load i64*, i64** %s, align 8
  %114 = load i64, i64* %l, align 8
  %shr129 = lshr i64 %114, 8
  %and130 = and i64 %shr129, 255
  %add131 = add i64 512, %and130
  %arrayidx132 = getelementptr inbounds i64, i64* %113, i64 %add131
  %115 = load i64, i64* %arrayidx132, align 8
  %xor133 = xor i64 %add128, %115
  %116 = load i64*, i64** %s, align 8
  %117 = load i64, i64* %l, align 8
  %and134 = and i64 %117, 255
  %add135 = add i64 768, %and134
  %arrayidx136 = getelementptr inbounds i64, i64* %116, i64 %add135
  %118 = load i64, i64* %arrayidx136, align 8
  %add137 = add i64 %xor133, %118
  %and138 = and i64 %add137, 4294967295
  %119 = load i64, i64* %r, align 8
  %xor139 = xor i64 %119, %and138
  store i64 %xor139, i64* %r, align 8
  %120 = load i64*, i64** %p, align 8
  %arrayidx140 = getelementptr inbounds i64, i64* %120, i64 8
  %121 = load i64, i64* %arrayidx140, align 8
  %122 = load i64, i64* %l, align 8
  %xor141 = xor i64 %122, %121
  store i64 %xor141, i64* %l, align 8
  %123 = load i64*, i64** %s, align 8
  %124 = load i64, i64* %r, align 8
  %shr142 = lshr i64 %124, 24
  %arrayidx143 = getelementptr inbounds i64, i64* %123, i64 %shr142
  %125 = load i64, i64* %arrayidx143, align 8
  %126 = load i64*, i64** %s, align 8
  %127 = load i64, i64* %r, align 8
  %shr144 = lshr i64 %127, 16
  %and145 = and i64 %shr144, 255
  %add146 = add i64 256, %and145
  %arrayidx147 = getelementptr inbounds i64, i64* %126, i64 %add146
  %128 = load i64, i64* %arrayidx147, align 8
  %add148 = add i64 %125, %128
  %129 = load i64*, i64** %s, align 8
  %130 = load i64, i64* %r, align 8
  %shr149 = lshr i64 %130, 8
  %and150 = and i64 %shr149, 255
  %add151 = add i64 512, %and150
  %arrayidx152 = getelementptr inbounds i64, i64* %129, i64 %add151
  %131 = load i64, i64* %arrayidx152, align 8
  %xor153 = xor i64 %add148, %131
  %132 = load i64*, i64** %s, align 8
  %133 = load i64, i64* %r, align 8
  %and154 = and i64 %133, 255
  %add155 = add i64 768, %and154
  %arrayidx156 = getelementptr inbounds i64, i64* %132, i64 %add155
  %134 = load i64, i64* %arrayidx156, align 8
  %add157 = add i64 %xor153, %134
  %and158 = and i64 %add157, 4294967295
  %135 = load i64, i64* %l, align 8
  %xor159 = xor i64 %135, %and158
  store i64 %xor159, i64* %l, align 8
  %136 = load i64*, i64** %p, align 8
  %arrayidx160 = getelementptr inbounds i64, i64* %136, i64 9
  %137 = load i64, i64* %arrayidx160, align 8
  %138 = load i64, i64* %r, align 8
  %xor161 = xor i64 %138, %137
  store i64 %xor161, i64* %r, align 8
  %139 = load i64*, i64** %s, align 8
  %140 = load i64, i64* %l, align 8
  %shr162 = lshr i64 %140, 24
  %arrayidx163 = getelementptr inbounds i64, i64* %139, i64 %shr162
  %141 = load i64, i64* %arrayidx163, align 8
  %142 = load i64*, i64** %s, align 8
  %143 = load i64, i64* %l, align 8
  %shr164 = lshr i64 %143, 16
  %and165 = and i64 %shr164, 255
  %add166 = add i64 256, %and165
  %arrayidx167 = getelementptr inbounds i64, i64* %142, i64 %add166
  %144 = load i64, i64* %arrayidx167, align 8
  %add168 = add i64 %141, %144
  %145 = load i64*, i64** %s, align 8
  %146 = load i64, i64* %l, align 8
  %shr169 = lshr i64 %146, 8
  %and170 = and i64 %shr169, 255
  %add171 = add i64 512, %and170
  %arrayidx172 = getelementptr inbounds i64, i64* %145, i64 %add171
  %147 = load i64, i64* %arrayidx172, align 8
  %xor173 = xor i64 %add168, %147
  %148 = load i64*, i64** %s, align 8
  %149 = load i64, i64* %l, align 8
  %and174 = and i64 %149, 255
  %add175 = add i64 768, %and174
  %arrayidx176 = getelementptr inbounds i64, i64* %148, i64 %add175
  %150 = load i64, i64* %arrayidx176, align 8
  %add177 = add i64 %xor173, %150
  %and178 = and i64 %add177, 4294967295
  %151 = load i64, i64* %r, align 8
  %xor179 = xor i64 %151, %and178
  store i64 %xor179, i64* %r, align 8
  %152 = load i64*, i64** %p, align 8
  %arrayidx180 = getelementptr inbounds i64, i64* %152, i64 10
  %153 = load i64, i64* %arrayidx180, align 8
  %154 = load i64, i64* %l, align 8
  %xor181 = xor i64 %154, %153
  store i64 %xor181, i64* %l, align 8
  %155 = load i64*, i64** %s, align 8
  %156 = load i64, i64* %r, align 8
  %shr182 = lshr i64 %156, 24
  %arrayidx183 = getelementptr inbounds i64, i64* %155, i64 %shr182
  %157 = load i64, i64* %arrayidx183, align 8
  %158 = load i64*, i64** %s, align 8
  %159 = load i64, i64* %r, align 8
  %shr184 = lshr i64 %159, 16
  %and185 = and i64 %shr184, 255
  %add186 = add i64 256, %and185
  %arrayidx187 = getelementptr inbounds i64, i64* %158, i64 %add186
  %160 = load i64, i64* %arrayidx187, align 8
  %add188 = add i64 %157, %160
  %161 = load i64*, i64** %s, align 8
  %162 = load i64, i64* %r, align 8
  %shr189 = lshr i64 %162, 8
  %and190 = and i64 %shr189, 255
  %add191 = add i64 512, %and190
  %arrayidx192 = getelementptr inbounds i64, i64* %161, i64 %add191
  %163 = load i64, i64* %arrayidx192, align 8
  %xor193 = xor i64 %add188, %163
  %164 = load i64*, i64** %s, align 8
  %165 = load i64, i64* %r, align 8
  %and194 = and i64 %165, 255
  %add195 = add i64 768, %and194
  %arrayidx196 = getelementptr inbounds i64, i64* %164, i64 %add195
  %166 = load i64, i64* %arrayidx196, align 8
  %add197 = add i64 %xor193, %166
  %and198 = and i64 %add197, 4294967295
  %167 = load i64, i64* %l, align 8
  %xor199 = xor i64 %167, %and198
  store i64 %xor199, i64* %l, align 8
  %168 = load i64*, i64** %p, align 8
  %arrayidx200 = getelementptr inbounds i64, i64* %168, i64 11
  %169 = load i64, i64* %arrayidx200, align 8
  %170 = load i64, i64* %r, align 8
  %xor201 = xor i64 %170, %169
  store i64 %xor201, i64* %r, align 8
  %171 = load i64*, i64** %s, align 8
  %172 = load i64, i64* %l, align 8
  %shr202 = lshr i64 %172, 24
  %arrayidx203 = getelementptr inbounds i64, i64* %171, i64 %shr202
  %173 = load i64, i64* %arrayidx203, align 8
  %174 = load i64*, i64** %s, align 8
  %175 = load i64, i64* %l, align 8
  %shr204 = lshr i64 %175, 16
  %and205 = and i64 %shr204, 255
  %add206 = add i64 256, %and205
  %arrayidx207 = getelementptr inbounds i64, i64* %174, i64 %add206
  %176 = load i64, i64* %arrayidx207, align 8
  %add208 = add i64 %173, %176
  %177 = load i64*, i64** %s, align 8
  %178 = load i64, i64* %l, align 8
  %shr209 = lshr i64 %178, 8
  %and210 = and i64 %shr209, 255
  %add211 = add i64 512, %and210
  %arrayidx212 = getelementptr inbounds i64, i64* %177, i64 %add211
  %179 = load i64, i64* %arrayidx212, align 8
  %xor213 = xor i64 %add208, %179
  %180 = load i64*, i64** %s, align 8
  %181 = load i64, i64* %l, align 8
  %and214 = and i64 %181, 255
  %add215 = add i64 768, %and214
  %arrayidx216 = getelementptr inbounds i64, i64* %180, i64 %add215
  %182 = load i64, i64* %arrayidx216, align 8
  %add217 = add i64 %xor213, %182
  %and218 = and i64 %add217, 4294967295
  %183 = load i64, i64* %r, align 8
  %xor219 = xor i64 %183, %and218
  store i64 %xor219, i64* %r, align 8
  %184 = load i64*, i64** %p, align 8
  %arrayidx220 = getelementptr inbounds i64, i64* %184, i64 12
  %185 = load i64, i64* %arrayidx220, align 8
  %186 = load i64, i64* %l, align 8
  %xor221 = xor i64 %186, %185
  store i64 %xor221, i64* %l, align 8
  %187 = load i64*, i64** %s, align 8
  %188 = load i64, i64* %r, align 8
  %shr222 = lshr i64 %188, 24
  %arrayidx223 = getelementptr inbounds i64, i64* %187, i64 %shr222
  %189 = load i64, i64* %arrayidx223, align 8
  %190 = load i64*, i64** %s, align 8
  %191 = load i64, i64* %r, align 8
  %shr224 = lshr i64 %191, 16
  %and225 = and i64 %shr224, 255
  %add226 = add i64 256, %and225
  %arrayidx227 = getelementptr inbounds i64, i64* %190, i64 %add226
  %192 = load i64, i64* %arrayidx227, align 8
  %add228 = add i64 %189, %192
  %193 = load i64*, i64** %s, align 8
  %194 = load i64, i64* %r, align 8
  %shr229 = lshr i64 %194, 8
  %and230 = and i64 %shr229, 255
  %add231 = add i64 512, %and230
  %arrayidx232 = getelementptr inbounds i64, i64* %193, i64 %add231
  %195 = load i64, i64* %arrayidx232, align 8
  %xor233 = xor i64 %add228, %195
  %196 = load i64*, i64** %s, align 8
  %197 = load i64, i64* %r, align 8
  %and234 = and i64 %197, 255
  %add235 = add i64 768, %and234
  %arrayidx236 = getelementptr inbounds i64, i64* %196, i64 %add235
  %198 = load i64, i64* %arrayidx236, align 8
  %add237 = add i64 %xor233, %198
  %and238 = and i64 %add237, 4294967295
  %199 = load i64, i64* %l, align 8
  %xor239 = xor i64 %199, %and238
  store i64 %xor239, i64* %l, align 8
  %200 = load i64*, i64** %p, align 8
  %arrayidx240 = getelementptr inbounds i64, i64* %200, i64 13
  %201 = load i64, i64* %arrayidx240, align 8
  %202 = load i64, i64* %r, align 8
  %xor241 = xor i64 %202, %201
  store i64 %xor241, i64* %r, align 8
  %203 = load i64*, i64** %s, align 8
  %204 = load i64, i64* %l, align 8
  %shr242 = lshr i64 %204, 24
  %arrayidx243 = getelementptr inbounds i64, i64* %203, i64 %shr242
  %205 = load i64, i64* %arrayidx243, align 8
  %206 = load i64*, i64** %s, align 8
  %207 = load i64, i64* %l, align 8
  %shr244 = lshr i64 %207, 16
  %and245 = and i64 %shr244, 255
  %add246 = add i64 256, %and245
  %arrayidx247 = getelementptr inbounds i64, i64* %206, i64 %add246
  %208 = load i64, i64* %arrayidx247, align 8
  %add248 = add i64 %205, %208
  %209 = load i64*, i64** %s, align 8
  %210 = load i64, i64* %l, align 8
  %shr249 = lshr i64 %210, 8
  %and250 = and i64 %shr249, 255
  %add251 = add i64 512, %and250
  %arrayidx252 = getelementptr inbounds i64, i64* %209, i64 %add251
  %211 = load i64, i64* %arrayidx252, align 8
  %xor253 = xor i64 %add248, %211
  %212 = load i64*, i64** %s, align 8
  %213 = load i64, i64* %l, align 8
  %and254 = and i64 %213, 255
  %add255 = add i64 768, %and254
  %arrayidx256 = getelementptr inbounds i64, i64* %212, i64 %add255
  %214 = load i64, i64* %arrayidx256, align 8
  %add257 = add i64 %xor253, %214
  %and258 = and i64 %add257, 4294967295
  %215 = load i64, i64* %r, align 8
  %xor259 = xor i64 %215, %and258
  store i64 %xor259, i64* %r, align 8
  %216 = load i64*, i64** %p, align 8
  %arrayidx260 = getelementptr inbounds i64, i64* %216, i64 14
  %217 = load i64, i64* %arrayidx260, align 8
  %218 = load i64, i64* %l, align 8
  %xor261 = xor i64 %218, %217
  store i64 %xor261, i64* %l, align 8
  %219 = load i64*, i64** %s, align 8
  %220 = load i64, i64* %r, align 8
  %shr262 = lshr i64 %220, 24
  %arrayidx263 = getelementptr inbounds i64, i64* %219, i64 %shr262
  %221 = load i64, i64* %arrayidx263, align 8
  %222 = load i64*, i64** %s, align 8
  %223 = load i64, i64* %r, align 8
  %shr264 = lshr i64 %223, 16
  %and265 = and i64 %shr264, 255
  %add266 = add i64 256, %and265
  %arrayidx267 = getelementptr inbounds i64, i64* %222, i64 %add266
  %224 = load i64, i64* %arrayidx267, align 8
  %add268 = add i64 %221, %224
  %225 = load i64*, i64** %s, align 8
  %226 = load i64, i64* %r, align 8
  %shr269 = lshr i64 %226, 8
  %and270 = and i64 %shr269, 255
  %add271 = add i64 512, %and270
  %arrayidx272 = getelementptr inbounds i64, i64* %225, i64 %add271
  %227 = load i64, i64* %arrayidx272, align 8
  %xor273 = xor i64 %add268, %227
  %228 = load i64*, i64** %s, align 8
  %229 = load i64, i64* %r, align 8
  %and274 = and i64 %229, 255
  %add275 = add i64 768, %and274
  %arrayidx276 = getelementptr inbounds i64, i64* %228, i64 %add275
  %230 = load i64, i64* %arrayidx276, align 8
  %add277 = add i64 %xor273, %230
  %and278 = and i64 %add277, 4294967295
  %231 = load i64, i64* %l, align 8
  %xor279 = xor i64 %231, %and278
  store i64 %xor279, i64* %l, align 8
  %232 = load i64*, i64** %p, align 8
  %arrayidx280 = getelementptr inbounds i64, i64* %232, i64 15
  %233 = load i64, i64* %arrayidx280, align 8
  %234 = load i64, i64* %r, align 8
  %xor281 = xor i64 %234, %233
  store i64 %xor281, i64* %r, align 8
  %235 = load i64*, i64** %s, align 8
  %236 = load i64, i64* %l, align 8
  %shr282 = lshr i64 %236, 24
  %arrayidx283 = getelementptr inbounds i64, i64* %235, i64 %shr282
  %237 = load i64, i64* %arrayidx283, align 8
  %238 = load i64*, i64** %s, align 8
  %239 = load i64, i64* %l, align 8
  %shr284 = lshr i64 %239, 16
  %and285 = and i64 %shr284, 255
  %add286 = add i64 256, %and285
  %arrayidx287 = getelementptr inbounds i64, i64* %238, i64 %add286
  %240 = load i64, i64* %arrayidx287, align 8
  %add288 = add i64 %237, %240
  %241 = load i64*, i64** %s, align 8
  %242 = load i64, i64* %l, align 8
  %shr289 = lshr i64 %242, 8
  %and290 = and i64 %shr289, 255
  %add291 = add i64 512, %and290
  %arrayidx292 = getelementptr inbounds i64, i64* %241, i64 %add291
  %243 = load i64, i64* %arrayidx292, align 8
  %xor293 = xor i64 %add288, %243
  %244 = load i64*, i64** %s, align 8
  %245 = load i64, i64* %l, align 8
  %and294 = and i64 %245, 255
  %add295 = add i64 768, %and294
  %arrayidx296 = getelementptr inbounds i64, i64* %244, i64 %add295
  %246 = load i64, i64* %arrayidx296, align 8
  %add297 = add i64 %xor293, %246
  %and298 = and i64 %add297, 4294967295
  %247 = load i64, i64* %r, align 8
  %xor299 = xor i64 %247, %and298
  store i64 %xor299, i64* %r, align 8
  %248 = load i64*, i64** %p, align 8
  %arrayidx300 = getelementptr inbounds i64, i64* %248, i64 16
  %249 = load i64, i64* %arrayidx300, align 8
  %250 = load i64, i64* %l, align 8
  %xor301 = xor i64 %250, %249
  store i64 %xor301, i64* %l, align 8
  %251 = load i64*, i64** %s, align 8
  %252 = load i64, i64* %r, align 8
  %shr302 = lshr i64 %252, 24
  %arrayidx303 = getelementptr inbounds i64, i64* %251, i64 %shr302
  %253 = load i64, i64* %arrayidx303, align 8
  %254 = load i64*, i64** %s, align 8
  %255 = load i64, i64* %r, align 8
  %shr304 = lshr i64 %255, 16
  %and305 = and i64 %shr304, 255
  %add306 = add i64 256, %and305
  %arrayidx307 = getelementptr inbounds i64, i64* %254, i64 %add306
  %256 = load i64, i64* %arrayidx307, align 8
  %add308 = add i64 %253, %256
  %257 = load i64*, i64** %s, align 8
  %258 = load i64, i64* %r, align 8
  %shr309 = lshr i64 %258, 8
  %and310 = and i64 %shr309, 255
  %add311 = add i64 512, %and310
  %arrayidx312 = getelementptr inbounds i64, i64* %257, i64 %add311
  %259 = load i64, i64* %arrayidx312, align 8
  %xor313 = xor i64 %add308, %259
  %260 = load i64*, i64** %s, align 8
  %261 = load i64, i64* %r, align 8
  %and314 = and i64 %261, 255
  %add315 = add i64 768, %and314
  %arrayidx316 = getelementptr inbounds i64, i64* %260, i64 %add315
  %262 = load i64, i64* %arrayidx316, align 8
  %add317 = add i64 %xor313, %262
  %and318 = and i64 %add317, 4294967295
  %263 = load i64, i64* %l, align 8
  %xor319 = xor i64 %263, %and318
  store i64 %xor319, i64* %l, align 8
  %264 = load i64*, i64** %p, align 8
  %arrayidx320 = getelementptr inbounds i64, i64* %264, i64 17
  %265 = load i64, i64* %arrayidx320, align 8
  %266 = load i64, i64* %r, align 8
  %xor321 = xor i64 %266, %265
  store i64 %xor321, i64* %r, align 8
  br label %if.end

if.else:                                          ; preds = %entry
  %267 = load i64*, i64** %p, align 8
  %arrayidx322 = getelementptr inbounds i64, i64* %267, i64 17
  %268 = load i64, i64* %arrayidx322, align 8
  %269 = load i64, i64* %l, align 8
  %xor323 = xor i64 %269, %268
  store i64 %xor323, i64* %l, align 8
  %270 = load i64*, i64** %p, align 8
  %arrayidx324 = getelementptr inbounds i64, i64* %270, i64 16
  %271 = load i64, i64* %arrayidx324, align 8
  %272 = load i64, i64* %r, align 8
  %xor325 = xor i64 %272, %271
  store i64 %xor325, i64* %r, align 8
  %273 = load i64*, i64** %s, align 8
  %274 = load i64, i64* %l, align 8
  %shr326 = lshr i64 %274, 24
  %arrayidx327 = getelementptr inbounds i64, i64* %273, i64 %shr326
  %275 = load i64, i64* %arrayidx327, align 8
  %276 = load i64*, i64** %s, align 8
  %277 = load i64, i64* %l, align 8
  %shr328 = lshr i64 %277, 16
  %and329 = and i64 %shr328, 255
  %add330 = add i64 256, %and329
  %arrayidx331 = getelementptr inbounds i64, i64* %276, i64 %add330
  %278 = load i64, i64* %arrayidx331, align 8
  %add332 = add i64 %275, %278
  %279 = load i64*, i64** %s, align 8
  %280 = load i64, i64* %l, align 8
  %shr333 = lshr i64 %280, 8
  %and334 = and i64 %shr333, 255
  %add335 = add i64 512, %and334
  %arrayidx336 = getelementptr inbounds i64, i64* %279, i64 %add335
  %281 = load i64, i64* %arrayidx336, align 8
  %xor337 = xor i64 %add332, %281
  %282 = load i64*, i64** %s, align 8
  %283 = load i64, i64* %l, align 8
  %and338 = and i64 %283, 255
  %add339 = add i64 768, %and338
  %arrayidx340 = getelementptr inbounds i64, i64* %282, i64 %add339
  %284 = load i64, i64* %arrayidx340, align 8
  %add341 = add i64 %xor337, %284
  %and342 = and i64 %add341, 4294967295
  %285 = load i64, i64* %r, align 8
  %xor343 = xor i64 %285, %and342
  store i64 %xor343, i64* %r, align 8
  %286 = load i64*, i64** %p, align 8
  %arrayidx344 = getelementptr inbounds i64, i64* %286, i64 15
  %287 = load i64, i64* %arrayidx344, align 8
  %288 = load i64, i64* %l, align 8
  %xor345 = xor i64 %288, %287
  store i64 %xor345, i64* %l, align 8
  %289 = load i64*, i64** %s, align 8
  %290 = load i64, i64* %r, align 8
  %shr346 = lshr i64 %290, 24
  %arrayidx347 = getelementptr inbounds i64, i64* %289, i64 %shr346
  %291 = load i64, i64* %arrayidx347, align 8
  %292 = load i64*, i64** %s, align 8
  %293 = load i64, i64* %r, align 8
  %shr348 = lshr i64 %293, 16
  %and349 = and i64 %shr348, 255
  %add350 = add i64 256, %and349
  %arrayidx351 = getelementptr inbounds i64, i64* %292, i64 %add350
  %294 = load i64, i64* %arrayidx351, align 8
  %add352 = add i64 %291, %294
  %295 = load i64*, i64** %s, align 8
  %296 = load i64, i64* %r, align 8
  %shr353 = lshr i64 %296, 8
  %and354 = and i64 %shr353, 255
  %add355 = add i64 512, %and354
  %arrayidx356 = getelementptr inbounds i64, i64* %295, i64 %add355
  %297 = load i64, i64* %arrayidx356, align 8
  %xor357 = xor i64 %add352, %297
  %298 = load i64*, i64** %s, align 8
  %299 = load i64, i64* %r, align 8
  %and358 = and i64 %299, 255
  %add359 = add i64 768, %and358
  %arrayidx360 = getelementptr inbounds i64, i64* %298, i64 %add359
  %300 = load i64, i64* %arrayidx360, align 8
  %add361 = add i64 %xor357, %300
  %and362 = and i64 %add361, 4294967295
  %301 = load i64, i64* %l, align 8
  %xor363 = xor i64 %301, %and362
  store i64 %xor363, i64* %l, align 8
  %302 = load i64*, i64** %p, align 8
  %arrayidx364 = getelementptr inbounds i64, i64* %302, i64 14
  %303 = load i64, i64* %arrayidx364, align 8
  %304 = load i64, i64* %r, align 8
  %xor365 = xor i64 %304, %303
  store i64 %xor365, i64* %r, align 8
  %305 = load i64*, i64** %s, align 8
  %306 = load i64, i64* %l, align 8
  %shr366 = lshr i64 %306, 24
  %arrayidx367 = getelementptr inbounds i64, i64* %305, i64 %shr366
  %307 = load i64, i64* %arrayidx367, align 8
  %308 = load i64*, i64** %s, align 8
  %309 = load i64, i64* %l, align 8
  %shr368 = lshr i64 %309, 16
  %and369 = and i64 %shr368, 255
  %add370 = add i64 256, %and369
  %arrayidx371 = getelementptr inbounds i64, i64* %308, i64 %add370
  %310 = load i64, i64* %arrayidx371, align 8
  %add372 = add i64 %307, %310
  %311 = load i64*, i64** %s, align 8
  %312 = load i64, i64* %l, align 8
  %shr373 = lshr i64 %312, 8
  %and374 = and i64 %shr373, 255
  %add375 = add i64 512, %and374
  %arrayidx376 = getelementptr inbounds i64, i64* %311, i64 %add375
  %313 = load i64, i64* %arrayidx376, align 8
  %xor377 = xor i64 %add372, %313
  %314 = load i64*, i64** %s, align 8
  %315 = load i64, i64* %l, align 8
  %and378 = and i64 %315, 255
  %add379 = add i64 768, %and378
  %arrayidx380 = getelementptr inbounds i64, i64* %314, i64 %add379
  %316 = load i64, i64* %arrayidx380, align 8
  %add381 = add i64 %xor377, %316
  %and382 = and i64 %add381, 4294967295
  %317 = load i64, i64* %r, align 8
  %xor383 = xor i64 %317, %and382
  store i64 %xor383, i64* %r, align 8
  %318 = load i64*, i64** %p, align 8
  %arrayidx384 = getelementptr inbounds i64, i64* %318, i64 13
  %319 = load i64, i64* %arrayidx384, align 8
  %320 = load i64, i64* %l, align 8
  %xor385 = xor i64 %320, %319
  store i64 %xor385, i64* %l, align 8
  %321 = load i64*, i64** %s, align 8
  %322 = load i64, i64* %r, align 8
  %shr386 = lshr i64 %322, 24
  %arrayidx387 = getelementptr inbounds i64, i64* %321, i64 %shr386
  %323 = load i64, i64* %arrayidx387, align 8
  %324 = load i64*, i64** %s, align 8
  %325 = load i64, i64* %r, align 8
  %shr388 = lshr i64 %325, 16
  %and389 = and i64 %shr388, 255
  %add390 = add i64 256, %and389
  %arrayidx391 = getelementptr inbounds i64, i64* %324, i64 %add390
  %326 = load i64, i64* %arrayidx391, align 8
  %add392 = add i64 %323, %326
  %327 = load i64*, i64** %s, align 8
  %328 = load i64, i64* %r, align 8
  %shr393 = lshr i64 %328, 8
  %and394 = and i64 %shr393, 255
  %add395 = add i64 512, %and394
  %arrayidx396 = getelementptr inbounds i64, i64* %327, i64 %add395
  %329 = load i64, i64* %arrayidx396, align 8
  %xor397 = xor i64 %add392, %329
  %330 = load i64*, i64** %s, align 8
  %331 = load i64, i64* %r, align 8
  %and398 = and i64 %331, 255
  %add399 = add i64 768, %and398
  %arrayidx400 = getelementptr inbounds i64, i64* %330, i64 %add399
  %332 = load i64, i64* %arrayidx400, align 8
  %add401 = add i64 %xor397, %332
  %and402 = and i64 %add401, 4294967295
  %333 = load i64, i64* %l, align 8
  %xor403 = xor i64 %333, %and402
  store i64 %xor403, i64* %l, align 8
  %334 = load i64*, i64** %p, align 8
  %arrayidx404 = getelementptr inbounds i64, i64* %334, i64 12
  %335 = load i64, i64* %arrayidx404, align 8
  %336 = load i64, i64* %r, align 8
  %xor405 = xor i64 %336, %335
  store i64 %xor405, i64* %r, align 8
  %337 = load i64*, i64** %s, align 8
  %338 = load i64, i64* %l, align 8
  %shr406 = lshr i64 %338, 24
  %arrayidx407 = getelementptr inbounds i64, i64* %337, i64 %shr406
  %339 = load i64, i64* %arrayidx407, align 8
  %340 = load i64*, i64** %s, align 8
  %341 = load i64, i64* %l, align 8
  %shr408 = lshr i64 %341, 16
  %and409 = and i64 %shr408, 255
  %add410 = add i64 256, %and409
  %arrayidx411 = getelementptr inbounds i64, i64* %340, i64 %add410
  %342 = load i64, i64* %arrayidx411, align 8
  %add412 = add i64 %339, %342
  %343 = load i64*, i64** %s, align 8
  %344 = load i64, i64* %l, align 8
  %shr413 = lshr i64 %344, 8
  %and414 = and i64 %shr413, 255
  %add415 = add i64 512, %and414
  %arrayidx416 = getelementptr inbounds i64, i64* %343, i64 %add415
  %345 = load i64, i64* %arrayidx416, align 8
  %xor417 = xor i64 %add412, %345
  %346 = load i64*, i64** %s, align 8
  %347 = load i64, i64* %l, align 8
  %and418 = and i64 %347, 255
  %add419 = add i64 768, %and418
  %arrayidx420 = getelementptr inbounds i64, i64* %346, i64 %add419
  %348 = load i64, i64* %arrayidx420, align 8
  %add421 = add i64 %xor417, %348
  %and422 = and i64 %add421, 4294967295
  %349 = load i64, i64* %r, align 8
  %xor423 = xor i64 %349, %and422
  store i64 %xor423, i64* %r, align 8
  %350 = load i64*, i64** %p, align 8
  %arrayidx424 = getelementptr inbounds i64, i64* %350, i64 11
  %351 = load i64, i64* %arrayidx424, align 8
  %352 = load i64, i64* %l, align 8
  %xor425 = xor i64 %352, %351
  store i64 %xor425, i64* %l, align 8
  %353 = load i64*, i64** %s, align 8
  %354 = load i64, i64* %r, align 8
  %shr426 = lshr i64 %354, 24
  %arrayidx427 = getelementptr inbounds i64, i64* %353, i64 %shr426
  %355 = load i64, i64* %arrayidx427, align 8
  %356 = load i64*, i64** %s, align 8
  %357 = load i64, i64* %r, align 8
  %shr428 = lshr i64 %357, 16
  %and429 = and i64 %shr428, 255
  %add430 = add i64 256, %and429
  %arrayidx431 = getelementptr inbounds i64, i64* %356, i64 %add430
  %358 = load i64, i64* %arrayidx431, align 8
  %add432 = add i64 %355, %358
  %359 = load i64*, i64** %s, align 8
  %360 = load i64, i64* %r, align 8
  %shr433 = lshr i64 %360, 8
  %and434 = and i64 %shr433, 255
  %add435 = add i64 512, %and434
  %arrayidx436 = getelementptr inbounds i64, i64* %359, i64 %add435
  %361 = load i64, i64* %arrayidx436, align 8
  %xor437 = xor i64 %add432, %361
  %362 = load i64*, i64** %s, align 8
  %363 = load i64, i64* %r, align 8
  %and438 = and i64 %363, 255
  %add439 = add i64 768, %and438
  %arrayidx440 = getelementptr inbounds i64, i64* %362, i64 %add439
  %364 = load i64, i64* %arrayidx440, align 8
  %add441 = add i64 %xor437, %364
  %and442 = and i64 %add441, 4294967295
  %365 = load i64, i64* %l, align 8
  %xor443 = xor i64 %365, %and442
  store i64 %xor443, i64* %l, align 8
  %366 = load i64*, i64** %p, align 8
  %arrayidx444 = getelementptr inbounds i64, i64* %366, i64 10
  %367 = load i64, i64* %arrayidx444, align 8
  %368 = load i64, i64* %r, align 8
  %xor445 = xor i64 %368, %367
  store i64 %xor445, i64* %r, align 8
  %369 = load i64*, i64** %s, align 8
  %370 = load i64, i64* %l, align 8
  %shr446 = lshr i64 %370, 24
  %arrayidx447 = getelementptr inbounds i64, i64* %369, i64 %shr446
  %371 = load i64, i64* %arrayidx447, align 8
  %372 = load i64*, i64** %s, align 8
  %373 = load i64, i64* %l, align 8
  %shr448 = lshr i64 %373, 16
  %and449 = and i64 %shr448, 255
  %add450 = add i64 256, %and449
  %arrayidx451 = getelementptr inbounds i64, i64* %372, i64 %add450
  %374 = load i64, i64* %arrayidx451, align 8
  %add452 = add i64 %371, %374
  %375 = load i64*, i64** %s, align 8
  %376 = load i64, i64* %l, align 8
  %shr453 = lshr i64 %376, 8
  %and454 = and i64 %shr453, 255
  %add455 = add i64 512, %and454
  %arrayidx456 = getelementptr inbounds i64, i64* %375, i64 %add455
  %377 = load i64, i64* %arrayidx456, align 8
  %xor457 = xor i64 %add452, %377
  %378 = load i64*, i64** %s, align 8
  %379 = load i64, i64* %l, align 8
  %and458 = and i64 %379, 255
  %add459 = add i64 768, %and458
  %arrayidx460 = getelementptr inbounds i64, i64* %378, i64 %add459
  %380 = load i64, i64* %arrayidx460, align 8
  %add461 = add i64 %xor457, %380
  %and462 = and i64 %add461, 4294967295
  %381 = load i64, i64* %r, align 8
  %xor463 = xor i64 %381, %and462
  store i64 %xor463, i64* %r, align 8
  %382 = load i64*, i64** %p, align 8
  %arrayidx464 = getelementptr inbounds i64, i64* %382, i64 9
  %383 = load i64, i64* %arrayidx464, align 8
  %384 = load i64, i64* %l, align 8
  %xor465 = xor i64 %384, %383
  store i64 %xor465, i64* %l, align 8
  %385 = load i64*, i64** %s, align 8
  %386 = load i64, i64* %r, align 8
  %shr466 = lshr i64 %386, 24
  %arrayidx467 = getelementptr inbounds i64, i64* %385, i64 %shr466
  %387 = load i64, i64* %arrayidx467, align 8
  %388 = load i64*, i64** %s, align 8
  %389 = load i64, i64* %r, align 8
  %shr468 = lshr i64 %389, 16
  %and469 = and i64 %shr468, 255
  %add470 = add i64 256, %and469
  %arrayidx471 = getelementptr inbounds i64, i64* %388, i64 %add470
  %390 = load i64, i64* %arrayidx471, align 8
  %add472 = add i64 %387, %390
  %391 = load i64*, i64** %s, align 8
  %392 = load i64, i64* %r, align 8
  %shr473 = lshr i64 %392, 8
  %and474 = and i64 %shr473, 255
  %add475 = add i64 512, %and474
  %arrayidx476 = getelementptr inbounds i64, i64* %391, i64 %add475
  %393 = load i64, i64* %arrayidx476, align 8
  %xor477 = xor i64 %add472, %393
  %394 = load i64*, i64** %s, align 8
  %395 = load i64, i64* %r, align 8
  %and478 = and i64 %395, 255
  %add479 = add i64 768, %and478
  %arrayidx480 = getelementptr inbounds i64, i64* %394, i64 %add479
  %396 = load i64, i64* %arrayidx480, align 8
  %add481 = add i64 %xor477, %396
  %and482 = and i64 %add481, 4294967295
  %397 = load i64, i64* %l, align 8
  %xor483 = xor i64 %397, %and482
  store i64 %xor483, i64* %l, align 8
  %398 = load i64*, i64** %p, align 8
  %arrayidx484 = getelementptr inbounds i64, i64* %398, i64 8
  %399 = load i64, i64* %arrayidx484, align 8
  %400 = load i64, i64* %r, align 8
  %xor485 = xor i64 %400, %399
  store i64 %xor485, i64* %r, align 8
  %401 = load i64*, i64** %s, align 8
  %402 = load i64, i64* %l, align 8
  %shr486 = lshr i64 %402, 24
  %arrayidx487 = getelementptr inbounds i64, i64* %401, i64 %shr486
  %403 = load i64, i64* %arrayidx487, align 8
  %404 = load i64*, i64** %s, align 8
  %405 = load i64, i64* %l, align 8
  %shr488 = lshr i64 %405, 16
  %and489 = and i64 %shr488, 255
  %add490 = add i64 256, %and489
  %arrayidx491 = getelementptr inbounds i64, i64* %404, i64 %add490
  %406 = load i64, i64* %arrayidx491, align 8
  %add492 = add i64 %403, %406
  %407 = load i64*, i64** %s, align 8
  %408 = load i64, i64* %l, align 8
  %shr493 = lshr i64 %408, 8
  %and494 = and i64 %shr493, 255
  %add495 = add i64 512, %and494
  %arrayidx496 = getelementptr inbounds i64, i64* %407, i64 %add495
  %409 = load i64, i64* %arrayidx496, align 8
  %xor497 = xor i64 %add492, %409
  %410 = load i64*, i64** %s, align 8
  %411 = load i64, i64* %l, align 8
  %and498 = and i64 %411, 255
  %add499 = add i64 768, %and498
  %arrayidx500 = getelementptr inbounds i64, i64* %410, i64 %add499
  %412 = load i64, i64* %arrayidx500, align 8
  %add501 = add i64 %xor497, %412
  %and502 = and i64 %add501, 4294967295
  %413 = load i64, i64* %r, align 8
  %xor503 = xor i64 %413, %and502
  store i64 %xor503, i64* %r, align 8
  %414 = load i64*, i64** %p, align 8
  %arrayidx504 = getelementptr inbounds i64, i64* %414, i64 7
  %415 = load i64, i64* %arrayidx504, align 8
  %416 = load i64, i64* %l, align 8
  %xor505 = xor i64 %416, %415
  store i64 %xor505, i64* %l, align 8
  %417 = load i64*, i64** %s, align 8
  %418 = load i64, i64* %r, align 8
  %shr506 = lshr i64 %418, 24
  %arrayidx507 = getelementptr inbounds i64, i64* %417, i64 %shr506
  %419 = load i64, i64* %arrayidx507, align 8
  %420 = load i64*, i64** %s, align 8
  %421 = load i64, i64* %r, align 8
  %shr508 = lshr i64 %421, 16
  %and509 = and i64 %shr508, 255
  %add510 = add i64 256, %and509
  %arrayidx511 = getelementptr inbounds i64, i64* %420, i64 %add510
  %422 = load i64, i64* %arrayidx511, align 8
  %add512 = add i64 %419, %422
  %423 = load i64*, i64** %s, align 8
  %424 = load i64, i64* %r, align 8
  %shr513 = lshr i64 %424, 8
  %and514 = and i64 %shr513, 255
  %add515 = add i64 512, %and514
  %arrayidx516 = getelementptr inbounds i64, i64* %423, i64 %add515
  %425 = load i64, i64* %arrayidx516, align 8
  %xor517 = xor i64 %add512, %425
  %426 = load i64*, i64** %s, align 8
  %427 = load i64, i64* %r, align 8
  %and518 = and i64 %427, 255
  %add519 = add i64 768, %and518
  %arrayidx520 = getelementptr inbounds i64, i64* %426, i64 %add519
  %428 = load i64, i64* %arrayidx520, align 8
  %add521 = add i64 %xor517, %428
  %and522 = and i64 %add521, 4294967295
  %429 = load i64, i64* %l, align 8
  %xor523 = xor i64 %429, %and522
  store i64 %xor523, i64* %l, align 8
  %430 = load i64*, i64** %p, align 8
  %arrayidx524 = getelementptr inbounds i64, i64* %430, i64 6
  %431 = load i64, i64* %arrayidx524, align 8
  %432 = load i64, i64* %r, align 8
  %xor525 = xor i64 %432, %431
  store i64 %xor525, i64* %r, align 8
  %433 = load i64*, i64** %s, align 8
  %434 = load i64, i64* %l, align 8
  %shr526 = lshr i64 %434, 24
  %arrayidx527 = getelementptr inbounds i64, i64* %433, i64 %shr526
  %435 = load i64, i64* %arrayidx527, align 8
  %436 = load i64*, i64** %s, align 8
  %437 = load i64, i64* %l, align 8
  %shr528 = lshr i64 %437, 16
  %and529 = and i64 %shr528, 255
  %add530 = add i64 256, %and529
  %arrayidx531 = getelementptr inbounds i64, i64* %436, i64 %add530
  %438 = load i64, i64* %arrayidx531, align 8
  %add532 = add i64 %435, %438
  %439 = load i64*, i64** %s, align 8
  %440 = load i64, i64* %l, align 8
  %shr533 = lshr i64 %440, 8
  %and534 = and i64 %shr533, 255
  %add535 = add i64 512, %and534
  %arrayidx536 = getelementptr inbounds i64, i64* %439, i64 %add535
  %441 = load i64, i64* %arrayidx536, align 8
  %xor537 = xor i64 %add532, %441
  %442 = load i64*, i64** %s, align 8
  %443 = load i64, i64* %l, align 8
  %and538 = and i64 %443, 255
  %add539 = add i64 768, %and538
  %arrayidx540 = getelementptr inbounds i64, i64* %442, i64 %add539
  %444 = load i64, i64* %arrayidx540, align 8
  %add541 = add i64 %xor537, %444
  %and542 = and i64 %add541, 4294967295
  %445 = load i64, i64* %r, align 8
  %xor543 = xor i64 %445, %and542
  store i64 %xor543, i64* %r, align 8
  %446 = load i64*, i64** %p, align 8
  %arrayidx544 = getelementptr inbounds i64, i64* %446, i64 5
  %447 = load i64, i64* %arrayidx544, align 8
  %448 = load i64, i64* %l, align 8
  %xor545 = xor i64 %448, %447
  store i64 %xor545, i64* %l, align 8
  %449 = load i64*, i64** %s, align 8
  %450 = load i64, i64* %r, align 8
  %shr546 = lshr i64 %450, 24
  %arrayidx547 = getelementptr inbounds i64, i64* %449, i64 %shr546
  %451 = load i64, i64* %arrayidx547, align 8
  %452 = load i64*, i64** %s, align 8
  %453 = load i64, i64* %r, align 8
  %shr548 = lshr i64 %453, 16
  %and549 = and i64 %shr548, 255
  %add550 = add i64 256, %and549
  %arrayidx551 = getelementptr inbounds i64, i64* %452, i64 %add550
  %454 = load i64, i64* %arrayidx551, align 8
  %add552 = add i64 %451, %454
  %455 = load i64*, i64** %s, align 8
  %456 = load i64, i64* %r, align 8
  %shr553 = lshr i64 %456, 8
  %and554 = and i64 %shr553, 255
  %add555 = add i64 512, %and554
  %arrayidx556 = getelementptr inbounds i64, i64* %455, i64 %add555
  %457 = load i64, i64* %arrayidx556, align 8
  %xor557 = xor i64 %add552, %457
  %458 = load i64*, i64** %s, align 8
  %459 = load i64, i64* %r, align 8
  %and558 = and i64 %459, 255
  %add559 = add i64 768, %and558
  %arrayidx560 = getelementptr inbounds i64, i64* %458, i64 %add559
  %460 = load i64, i64* %arrayidx560, align 8
  %add561 = add i64 %xor557, %460
  %and562 = and i64 %add561, 4294967295
  %461 = load i64, i64* %l, align 8
  %xor563 = xor i64 %461, %and562
  store i64 %xor563, i64* %l, align 8
  %462 = load i64*, i64** %p, align 8
  %arrayidx564 = getelementptr inbounds i64, i64* %462, i64 4
  %463 = load i64, i64* %arrayidx564, align 8
  %464 = load i64, i64* %r, align 8
  %xor565 = xor i64 %464, %463
  store i64 %xor565, i64* %r, align 8
  %465 = load i64*, i64** %s, align 8
  %466 = load i64, i64* %l, align 8
  %shr566 = lshr i64 %466, 24
  %arrayidx567 = getelementptr inbounds i64, i64* %465, i64 %shr566
  %467 = load i64, i64* %arrayidx567, align 8
  %468 = load i64*, i64** %s, align 8
  %469 = load i64, i64* %l, align 8
  %shr568 = lshr i64 %469, 16
  %and569 = and i64 %shr568, 255
  %add570 = add i64 256, %and569
  %arrayidx571 = getelementptr inbounds i64, i64* %468, i64 %add570
  %470 = load i64, i64* %arrayidx571, align 8
  %add572 = add i64 %467, %470
  %471 = load i64*, i64** %s, align 8
  %472 = load i64, i64* %l, align 8
  %shr573 = lshr i64 %472, 8
  %and574 = and i64 %shr573, 255
  %add575 = add i64 512, %and574
  %arrayidx576 = getelementptr inbounds i64, i64* %471, i64 %add575
  %473 = load i64, i64* %arrayidx576, align 8
  %xor577 = xor i64 %add572, %473
  %474 = load i64*, i64** %s, align 8
  %475 = load i64, i64* %l, align 8
  %and578 = and i64 %475, 255
  %add579 = add i64 768, %and578
  %arrayidx580 = getelementptr inbounds i64, i64* %474, i64 %add579
  %476 = load i64, i64* %arrayidx580, align 8
  %add581 = add i64 %xor577, %476
  %and582 = and i64 %add581, 4294967295
  %477 = load i64, i64* %r, align 8
  %xor583 = xor i64 %477, %and582
  store i64 %xor583, i64* %r, align 8
  %478 = load i64*, i64** %p, align 8
  %arrayidx584 = getelementptr inbounds i64, i64* %478, i64 3
  %479 = load i64, i64* %arrayidx584, align 8
  %480 = load i64, i64* %l, align 8
  %xor585 = xor i64 %480, %479
  store i64 %xor585, i64* %l, align 8
  %481 = load i64*, i64** %s, align 8
  %482 = load i64, i64* %r, align 8
  %shr586 = lshr i64 %482, 24
  %arrayidx587 = getelementptr inbounds i64, i64* %481, i64 %shr586
  %483 = load i64, i64* %arrayidx587, align 8
  %484 = load i64*, i64** %s, align 8
  %485 = load i64, i64* %r, align 8
  %shr588 = lshr i64 %485, 16
  %and589 = and i64 %shr588, 255
  %add590 = add i64 256, %and589
  %arrayidx591 = getelementptr inbounds i64, i64* %484, i64 %add590
  %486 = load i64, i64* %arrayidx591, align 8
  %add592 = add i64 %483, %486
  %487 = load i64*, i64** %s, align 8
  %488 = load i64, i64* %r, align 8
  %shr593 = lshr i64 %488, 8
  %and594 = and i64 %shr593, 255
  %add595 = add i64 512, %and594
  %arrayidx596 = getelementptr inbounds i64, i64* %487, i64 %add595
  %489 = load i64, i64* %arrayidx596, align 8
  %xor597 = xor i64 %add592, %489
  %490 = load i64*, i64** %s, align 8
  %491 = load i64, i64* %r, align 8
  %and598 = and i64 %491, 255
  %add599 = add i64 768, %and598
  %arrayidx600 = getelementptr inbounds i64, i64* %490, i64 %add599
  %492 = load i64, i64* %arrayidx600, align 8
  %add601 = add i64 %xor597, %492
  %and602 = and i64 %add601, 4294967295
  %493 = load i64, i64* %l, align 8
  %xor603 = xor i64 %493, %and602
  store i64 %xor603, i64* %l, align 8
  %494 = load i64*, i64** %p, align 8
  %arrayidx604 = getelementptr inbounds i64, i64* %494, i64 2
  %495 = load i64, i64* %arrayidx604, align 8
  %496 = load i64, i64* %r, align 8
  %xor605 = xor i64 %496, %495
  store i64 %xor605, i64* %r, align 8
  %497 = load i64*, i64** %s, align 8
  %498 = load i64, i64* %l, align 8
  %shr606 = lshr i64 %498, 24
  %arrayidx607 = getelementptr inbounds i64, i64* %497, i64 %shr606
  %499 = load i64, i64* %arrayidx607, align 8
  %500 = load i64*, i64** %s, align 8
  %501 = load i64, i64* %l, align 8
  %shr608 = lshr i64 %501, 16
  %and609 = and i64 %shr608, 255
  %add610 = add i64 256, %and609
  %arrayidx611 = getelementptr inbounds i64, i64* %500, i64 %add610
  %502 = load i64, i64* %arrayidx611, align 8
  %add612 = add i64 %499, %502
  %503 = load i64*, i64** %s, align 8
  %504 = load i64, i64* %l, align 8
  %shr613 = lshr i64 %504, 8
  %and614 = and i64 %shr613, 255
  %add615 = add i64 512, %and614
  %arrayidx616 = getelementptr inbounds i64, i64* %503, i64 %add615
  %505 = load i64, i64* %arrayidx616, align 8
  %xor617 = xor i64 %add612, %505
  %506 = load i64*, i64** %s, align 8
  %507 = load i64, i64* %l, align 8
  %and618 = and i64 %507, 255
  %add619 = add i64 768, %and618
  %arrayidx620 = getelementptr inbounds i64, i64* %506, i64 %add619
  %508 = load i64, i64* %arrayidx620, align 8
  %add621 = add i64 %xor617, %508
  %and622 = and i64 %add621, 4294967295
  %509 = load i64, i64* %r, align 8
  %xor623 = xor i64 %509, %and622
  store i64 %xor623, i64* %r, align 8
  %510 = load i64*, i64** %p, align 8
  %arrayidx624 = getelementptr inbounds i64, i64* %510, i64 1
  %511 = load i64, i64* %arrayidx624, align 8
  %512 = load i64, i64* %l, align 8
  %xor625 = xor i64 %512, %511
  store i64 %xor625, i64* %l, align 8
  %513 = load i64*, i64** %s, align 8
  %514 = load i64, i64* %r, align 8
  %shr626 = lshr i64 %514, 24
  %arrayidx627 = getelementptr inbounds i64, i64* %513, i64 %shr626
  %515 = load i64, i64* %arrayidx627, align 8
  %516 = load i64*, i64** %s, align 8
  %517 = load i64, i64* %r, align 8
  %shr628 = lshr i64 %517, 16
  %and629 = and i64 %shr628, 255
  %add630 = add i64 256, %and629
  %arrayidx631 = getelementptr inbounds i64, i64* %516, i64 %add630
  %518 = load i64, i64* %arrayidx631, align 8
  %add632 = add i64 %515, %518
  %519 = load i64*, i64** %s, align 8
  %520 = load i64, i64* %r, align 8
  %shr633 = lshr i64 %520, 8
  %and634 = and i64 %shr633, 255
  %add635 = add i64 512, %and634
  %arrayidx636 = getelementptr inbounds i64, i64* %519, i64 %add635
  %521 = load i64, i64* %arrayidx636, align 8
  %xor637 = xor i64 %add632, %521
  %522 = load i64*, i64** %s, align 8
  %523 = load i64, i64* %r, align 8
  %and638 = and i64 %523, 255
  %add639 = add i64 768, %and638
  %arrayidx640 = getelementptr inbounds i64, i64* %522, i64 %add639
  %524 = load i64, i64* %arrayidx640, align 8
  %add641 = add i64 %xor637, %524
  %and642 = and i64 %add641, 4294967295
  %525 = load i64, i64* %l, align 8
  %xor643 = xor i64 %525, %and642
  store i64 %xor643, i64* %l, align 8
  %526 = load i64*, i64** %p, align 8
  %arrayidx644 = getelementptr inbounds i64, i64* %526, i64 0
  %527 = load i64, i64* %arrayidx644, align 8
  %528 = load i64, i64* %r, align 8
  %xor645 = xor i64 %528, %527
  store i64 %xor645, i64* %r, align 8
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  %529 = load i64, i64* %l, align 8
  %and646 = and i64 %529, 4294967295
  %530 = load i64*, i64** %data.addr, align 8
  %arrayidx647 = getelementptr inbounds i64, i64* %530, i64 1
  store i64 %and646, i64* %arrayidx647, align 8
  %531 = load i64, i64* %r, align 8
  %and648 = and i64 %531, 4294967295
  %532 = load i64*, i64** %data.addr, align 8
  %arrayidx649 = getelementptr inbounds i64, i64* %532, i64 0
  store i64 %and648, i64* %arrayidx649, align 8
  ret void
}

; Function Attrs: noinline nounwind ssp uwtable
define void @BF_cfb64_encrypt(i8* %in, i8* %out, i64 %length, i8* %ivec, i32* %num, i32 %encrypt) #0 {
entry:
  %in.addr = alloca i8*, align 8
  %out.addr = alloca i8*, align 8
  %length.addr = alloca i64, align 8
  %ivec.addr = alloca i8*, align 8
  %num.addr = alloca i32*, align 8
  %encrypt.addr = alloca i32, align 4
  %v0 = alloca i64, align 8
  %v1 = alloca i64, align 8
  %t = alloca i64, align 8
  %n = alloca i32, align 4
  %l = alloca i64, align 8
  %ti = alloca [2 x i64], align 16
  %iv = alloca i8*, align 8
  %c = alloca i8, align 1
  %cc = alloca i8, align 1
  store i8* %in, i8** %in.addr, align 8
  store i8* %out, i8** %out.addr, align 8
  store i64 %length, i64* %length.addr, align 8
  store i8* %ivec, i8** %ivec.addr, align 8
  store i32* %num, i32** %num.addr, align 8
  store i32 %encrypt, i32* %encrypt.addr, align 4
  %0 = load i32*, i32** %num.addr, align 8
  %1 = load i32, i32* %0, align 4
  store i32 %1, i32* %n, align 4
  %2 = load i64, i64* %length.addr, align 8
  store i64 %2, i64* %l, align 8
  %3 = load i8*, i8** %ivec.addr, align 8
  store i8* %3, i8** %iv, align 8
  %4 = load i32, i32* %encrypt.addr, align 4
  %tobool = icmp ne i32 %4, 0
  br i1 %tobool, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  br label %while.cond

while.cond:                                       ; preds = %if.end, %if.then
  %5 = load i64, i64* %l, align 8
  %dec = add nsw i64 %5, -1
  store i64 %dec, i64* %l, align 8
  %tobool1 = icmp ne i64 %5, 0
  br i1 %tobool1, label %while.body, label %while.end

while.body:                                       ; preds = %while.cond
  %6 = load i32, i32* %n, align 4
  %cmp = icmp eq i32 %6, 0
  br i1 %cmp, label %if.then2, label %if.end

if.then2:                                         ; preds = %while.body
  %7 = load i8*, i8** %iv, align 8
  %incdec.ptr = getelementptr inbounds i8, i8* %7, i32 1
  store i8* %incdec.ptr, i8** %iv, align 8
  %8 = load i8, i8* %7, align 1
  %conv = zext i8 %8 to i64
  %shl = shl i64 %conv, 24
  store i64 %shl, i64* %v0, align 8
  %9 = load i8*, i8** %iv, align 8
  %incdec.ptr3 = getelementptr inbounds i8, i8* %9, i32 1
  store i8* %incdec.ptr3, i8** %iv, align 8
  %10 = load i8, i8* %9, align 1
  %conv4 = zext i8 %10 to i64
  %shl5 = shl i64 %conv4, 16
  %11 = load i64, i64* %v0, align 8
  %or = or i64 %11, %shl5
  store i64 %or, i64* %v0, align 8
  %12 = load i8*, i8** %iv, align 8
  %incdec.ptr6 = getelementptr inbounds i8, i8* %12, i32 1
  store i8* %incdec.ptr6, i8** %iv, align 8
  %13 = load i8, i8* %12, align 1
  %conv7 = zext i8 %13 to i64
  %shl8 = shl i64 %conv7, 8
  %14 = load i64, i64* %v0, align 8
  %or9 = or i64 %14, %shl8
  store i64 %or9, i64* %v0, align 8
  %15 = load i8*, i8** %iv, align 8
  %incdec.ptr10 = getelementptr inbounds i8, i8* %15, i32 1
  store i8* %incdec.ptr10, i8** %iv, align 8
  %16 = load i8, i8* %15, align 1
  %conv11 = zext i8 %16 to i64
  %17 = load i64, i64* %v0, align 8
  %or12 = or i64 %17, %conv11
  store i64 %or12, i64* %v0, align 8
  %18 = load i64, i64* %v0, align 8
  %arrayidx = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 0
  store i64 %18, i64* %arrayidx, align 16
  %19 = load i8*, i8** %iv, align 8
  %incdec.ptr13 = getelementptr inbounds i8, i8* %19, i32 1
  store i8* %incdec.ptr13, i8** %iv, align 8
  %20 = load i8, i8* %19, align 1
  %conv14 = zext i8 %20 to i64
  %shl15 = shl i64 %conv14, 24
  store i64 %shl15, i64* %v1, align 8
  %21 = load i8*, i8** %iv, align 8
  %incdec.ptr16 = getelementptr inbounds i8, i8* %21, i32 1
  store i8* %incdec.ptr16, i8** %iv, align 8
  %22 = load i8, i8* %21, align 1
  %conv17 = zext i8 %22 to i64
  %shl18 = shl i64 %conv17, 16
  %23 = load i64, i64* %v1, align 8
  %or19 = or i64 %23, %shl18
  store i64 %or19, i64* %v1, align 8
  %24 = load i8*, i8** %iv, align 8
  %incdec.ptr20 = getelementptr inbounds i8, i8* %24, i32 1
  store i8* %incdec.ptr20, i8** %iv, align 8
  %25 = load i8, i8* %24, align 1
  %conv21 = zext i8 %25 to i64
  %shl22 = shl i64 %conv21, 8
  %26 = load i64, i64* %v1, align 8
  %or23 = or i64 %26, %shl22
  store i64 %or23, i64* %v1, align 8
  %27 = load i8*, i8** %iv, align 8
  %incdec.ptr24 = getelementptr inbounds i8, i8* %27, i32 1
  store i8* %incdec.ptr24, i8** %iv, align 8
  %28 = load i8, i8* %27, align 1
  %conv25 = zext i8 %28 to i64
  %29 = load i64, i64* %v1, align 8
  %or26 = or i64 %29, %conv25
  store i64 %or26, i64* %v1, align 8
  %30 = load i64, i64* %v1, align 8
  %arrayidx27 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 1
  store i64 %30, i64* %arrayidx27, align 8
  %arraydecay = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i32 0, i32 0
  call void @BF_encrypt(i64* %arraydecay, i32 1)
  %31 = load i8*, i8** %ivec.addr, align 8
  store i8* %31, i8** %iv, align 8
  %arrayidx28 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 0
  %32 = load i64, i64* %arrayidx28, align 16
  store i64 %32, i64* %t, align 8
  %33 = load i64, i64* %t, align 8
  %shr = lshr i64 %33, 24
  %and = and i64 %shr, 255
  %conv29 = trunc i64 %and to i8
  %34 = load i8*, i8** %iv, align 8
  %incdec.ptr30 = getelementptr inbounds i8, i8* %34, i32 1
  store i8* %incdec.ptr30, i8** %iv, align 8
  store i8 %conv29, i8* %34, align 1
  %35 = load i64, i64* %t, align 8
  %shr31 = lshr i64 %35, 16
  %and32 = and i64 %shr31, 255
  %conv33 = trunc i64 %and32 to i8
  %36 = load i8*, i8** %iv, align 8
  %incdec.ptr34 = getelementptr inbounds i8, i8* %36, i32 1
  store i8* %incdec.ptr34, i8** %iv, align 8
  store i8 %conv33, i8* %36, align 1
  %37 = load i64, i64* %t, align 8
  %shr35 = lshr i64 %37, 8
  %and36 = and i64 %shr35, 255
  %conv37 = trunc i64 %and36 to i8
  %38 = load i8*, i8** %iv, align 8
  %incdec.ptr38 = getelementptr inbounds i8, i8* %38, i32 1
  store i8* %incdec.ptr38, i8** %iv, align 8
  store i8 %conv37, i8* %38, align 1
  %39 = load i64, i64* %t, align 8
  %and39 = and i64 %39, 255
  %conv40 = trunc i64 %and39 to i8
  %40 = load i8*, i8** %iv, align 8
  %incdec.ptr41 = getelementptr inbounds i8, i8* %40, i32 1
  store i8* %incdec.ptr41, i8** %iv, align 8
  store i8 %conv40, i8* %40, align 1
  %arrayidx42 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 1
  %41 = load i64, i64* %arrayidx42, align 8
  store i64 %41, i64* %t, align 8
  %42 = load i64, i64* %t, align 8
  %shr43 = lshr i64 %42, 24
  %and44 = and i64 %shr43, 255
  %conv45 = trunc i64 %and44 to i8
  %43 = load i8*, i8** %iv, align 8
  %incdec.ptr46 = getelementptr inbounds i8, i8* %43, i32 1
  store i8* %incdec.ptr46, i8** %iv, align 8
  store i8 %conv45, i8* %43, align 1
  %44 = load i64, i64* %t, align 8
  %shr47 = lshr i64 %44, 16
  %and48 = and i64 %shr47, 255
  %conv49 = trunc i64 %and48 to i8
  %45 = load i8*, i8** %iv, align 8
  %incdec.ptr50 = getelementptr inbounds i8, i8* %45, i32 1
  store i8* %incdec.ptr50, i8** %iv, align 8
  store i8 %conv49, i8* %45, align 1
  %46 = load i64, i64* %t, align 8
  %shr51 = lshr i64 %46, 8
  %and52 = and i64 %shr51, 255
  %conv53 = trunc i64 %and52 to i8
  %47 = load i8*, i8** %iv, align 8
  %incdec.ptr54 = getelementptr inbounds i8, i8* %47, i32 1
  store i8* %incdec.ptr54, i8** %iv, align 8
  store i8 %conv53, i8* %47, align 1
  %48 = load i64, i64* %t, align 8
  %and55 = and i64 %48, 255
  %conv56 = trunc i64 %and55 to i8
  %49 = load i8*, i8** %iv, align 8
  %incdec.ptr57 = getelementptr inbounds i8, i8* %49, i32 1
  store i8* %incdec.ptr57, i8** %iv, align 8
  store i8 %conv56, i8* %49, align 1
  %50 = load i8*, i8** %ivec.addr, align 8
  store i8* %50, i8** %iv, align 8
  br label %if.end

if.end:                                           ; preds = %if.then2, %while.body
  %51 = load i8*, i8** %in.addr, align 8
  %incdec.ptr58 = getelementptr inbounds i8, i8* %51, i32 1
  store i8* %incdec.ptr58, i8** %in.addr, align 8
  %52 = load i8, i8* %51, align 1
  %conv59 = zext i8 %52 to i32
  %53 = load i8*, i8** %iv, align 8
  %54 = load i32, i32* %n, align 4
  %idxprom = sext i32 %54 to i64
  %arrayidx60 = getelementptr inbounds i8, i8* %53, i64 %idxprom
  %55 = load i8, i8* %arrayidx60, align 1
  %conv61 = zext i8 %55 to i32
  %xor = xor i32 %conv59, %conv61
  %conv62 = trunc i32 %xor to i8
  store i8 %conv62, i8* %c, align 1
  %56 = load i8, i8* %c, align 1
  %57 = load i8*, i8** %out.addr, align 8
  %incdec.ptr63 = getelementptr inbounds i8, i8* %57, i32 1
  store i8* %incdec.ptr63, i8** %out.addr, align 8
  store i8 %56, i8* %57, align 1
  %58 = load i8, i8* %c, align 1
  %59 = load i8*, i8** %iv, align 8
  %60 = load i32, i32* %n, align 4
  %idxprom64 = sext i32 %60 to i64
  %arrayidx65 = getelementptr inbounds i8, i8* %59, i64 %idxprom64
  store i8 %58, i8* %arrayidx65, align 1
  %61 = load i32, i32* %n, align 4
  %add = add nsw i32 %61, 1
  %and66 = and i32 %add, 7
  store i32 %and66, i32* %n, align 4
  br label %while.cond

while.end:                                        ; preds = %while.cond
  br label %if.end151

if.else:                                          ; preds = %entry
  br label %while.cond67

while.cond67:                                     ; preds = %if.end137, %if.else
  %62 = load i64, i64* %l, align 8
  %dec68 = add nsw i64 %62, -1
  store i64 %dec68, i64* %l, align 8
  %tobool69 = icmp ne i64 %62, 0
  br i1 %tobool69, label %while.body70, label %while.end150

while.body70:                                     ; preds = %while.cond67
  %63 = load i32, i32* %n, align 4
  %cmp71 = icmp eq i32 %63, 0
  br i1 %cmp71, label %if.then73, label %if.end137

if.then73:                                        ; preds = %while.body70
  %64 = load i8*, i8** %iv, align 8
  %incdec.ptr74 = getelementptr inbounds i8, i8* %64, i32 1
  store i8* %incdec.ptr74, i8** %iv, align 8
  %65 = load i8, i8* %64, align 1
  %conv75 = zext i8 %65 to i64
  %shl76 = shl i64 %conv75, 24
  store i64 %shl76, i64* %v0, align 8
  %66 = load i8*, i8** %iv, align 8
  %incdec.ptr77 = getelementptr inbounds i8, i8* %66, i32 1
  store i8* %incdec.ptr77, i8** %iv, align 8
  %67 = load i8, i8* %66, align 1
  %conv78 = zext i8 %67 to i64
  %shl79 = shl i64 %conv78, 16
  %68 = load i64, i64* %v0, align 8
  %or80 = or i64 %68, %shl79
  store i64 %or80, i64* %v0, align 8
  %69 = load i8*, i8** %iv, align 8
  %incdec.ptr81 = getelementptr inbounds i8, i8* %69, i32 1
  store i8* %incdec.ptr81, i8** %iv, align 8
  %70 = load i8, i8* %69, align 1
  %conv82 = zext i8 %70 to i64
  %shl83 = shl i64 %conv82, 8
  %71 = load i64, i64* %v0, align 8
  %or84 = or i64 %71, %shl83
  store i64 %or84, i64* %v0, align 8
  %72 = load i8*, i8** %iv, align 8
  %incdec.ptr85 = getelementptr inbounds i8, i8* %72, i32 1
  store i8* %incdec.ptr85, i8** %iv, align 8
  %73 = load i8, i8* %72, align 1
  %conv86 = zext i8 %73 to i64
  %74 = load i64, i64* %v0, align 8
  %or87 = or i64 %74, %conv86
  store i64 %or87, i64* %v0, align 8
  %75 = load i64, i64* %v0, align 8
  %arrayidx88 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 0
  store i64 %75, i64* %arrayidx88, align 16
  %76 = load i8*, i8** %iv, align 8
  %incdec.ptr89 = getelementptr inbounds i8, i8* %76, i32 1
  store i8* %incdec.ptr89, i8** %iv, align 8
  %77 = load i8, i8* %76, align 1
  %conv90 = zext i8 %77 to i64
  %shl91 = shl i64 %conv90, 24
  store i64 %shl91, i64* %v1, align 8
  %78 = load i8*, i8** %iv, align 8
  %incdec.ptr92 = getelementptr inbounds i8, i8* %78, i32 1
  store i8* %incdec.ptr92, i8** %iv, align 8
  %79 = load i8, i8* %78, align 1
  %conv93 = zext i8 %79 to i64
  %shl94 = shl i64 %conv93, 16
  %80 = load i64, i64* %v1, align 8
  %or95 = or i64 %80, %shl94
  store i64 %or95, i64* %v1, align 8
  %81 = load i8*, i8** %iv, align 8
  %incdec.ptr96 = getelementptr inbounds i8, i8* %81, i32 1
  store i8* %incdec.ptr96, i8** %iv, align 8
  %82 = load i8, i8* %81, align 1
  %conv97 = zext i8 %82 to i64
  %shl98 = shl i64 %conv97, 8
  %83 = load i64, i64* %v1, align 8
  %or99 = or i64 %83, %shl98
  store i64 %or99, i64* %v1, align 8
  %84 = load i8*, i8** %iv, align 8
  %incdec.ptr100 = getelementptr inbounds i8, i8* %84, i32 1
  store i8* %incdec.ptr100, i8** %iv, align 8
  %85 = load i8, i8* %84, align 1
  %conv101 = zext i8 %85 to i64
  %86 = load i64, i64* %v1, align 8
  %or102 = or i64 %86, %conv101
  store i64 %or102, i64* %v1, align 8
  %87 = load i64, i64* %v1, align 8
  %arrayidx103 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 1
  store i64 %87, i64* %arrayidx103, align 8
  %arraydecay104 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i32 0, i32 0
  call void @BF_encrypt(i64* %arraydecay104, i32 1)
  %88 = load i8*, i8** %ivec.addr, align 8
  store i8* %88, i8** %iv, align 8
  %arrayidx105 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 0
  %89 = load i64, i64* %arrayidx105, align 16
  store i64 %89, i64* %t, align 8
  %90 = load i64, i64* %t, align 8
  %shr106 = lshr i64 %90, 24
  %and107 = and i64 %shr106, 255
  %conv108 = trunc i64 %and107 to i8
  %91 = load i8*, i8** %iv, align 8
  %incdec.ptr109 = getelementptr inbounds i8, i8* %91, i32 1
  store i8* %incdec.ptr109, i8** %iv, align 8
  store i8 %conv108, i8* %91, align 1
  %92 = load i64, i64* %t, align 8
  %shr110 = lshr i64 %92, 16
  %and111 = and i64 %shr110, 255
  %conv112 = trunc i64 %and111 to i8
  %93 = load i8*, i8** %iv, align 8
  %incdec.ptr113 = getelementptr inbounds i8, i8* %93, i32 1
  store i8* %incdec.ptr113, i8** %iv, align 8
  store i8 %conv112, i8* %93, align 1
  %94 = load i64, i64* %t, align 8
  %shr114 = lshr i64 %94, 8
  %and115 = and i64 %shr114, 255
  %conv116 = trunc i64 %and115 to i8
  %95 = load i8*, i8** %iv, align 8
  %incdec.ptr117 = getelementptr inbounds i8, i8* %95, i32 1
  store i8* %incdec.ptr117, i8** %iv, align 8
  store i8 %conv116, i8* %95, align 1
  %96 = load i64, i64* %t, align 8
  %and118 = and i64 %96, 255
  %conv119 = trunc i64 %and118 to i8
  %97 = load i8*, i8** %iv, align 8
  %incdec.ptr120 = getelementptr inbounds i8, i8* %97, i32 1
  store i8* %incdec.ptr120, i8** %iv, align 8
  store i8 %conv119, i8* %97, align 1
  %arrayidx121 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 1
  %98 = load i64, i64* %arrayidx121, align 8
  store i64 %98, i64* %t, align 8
  %99 = load i64, i64* %t, align 8
  %shr122 = lshr i64 %99, 24
  %and123 = and i64 %shr122, 255
  %conv124 = trunc i64 %and123 to i8
  %100 = load i8*, i8** %iv, align 8
  %incdec.ptr125 = getelementptr inbounds i8, i8* %100, i32 1
  store i8* %incdec.ptr125, i8** %iv, align 8
  store i8 %conv124, i8* %100, align 1
  %101 = load i64, i64* %t, align 8
  %shr126 = lshr i64 %101, 16
  %and127 = and i64 %shr126, 255
  %conv128 = trunc i64 %and127 to i8
  %102 = load i8*, i8** %iv, align 8
  %incdec.ptr129 = getelementptr inbounds i8, i8* %102, i32 1
  store i8* %incdec.ptr129, i8** %iv, align 8
  store i8 %conv128, i8* %102, align 1
  %103 = load i64, i64* %t, align 8
  %shr130 = lshr i64 %103, 8
  %and131 = and i64 %shr130, 255
  %conv132 = trunc i64 %and131 to i8
  %104 = load i8*, i8** %iv, align 8
  %incdec.ptr133 = getelementptr inbounds i8, i8* %104, i32 1
  store i8* %incdec.ptr133, i8** %iv, align 8
  store i8 %conv132, i8* %104, align 1
  %105 = load i64, i64* %t, align 8
  %and134 = and i64 %105, 255
  %conv135 = trunc i64 %and134 to i8
  %106 = load i8*, i8** %iv, align 8
  %incdec.ptr136 = getelementptr inbounds i8, i8* %106, i32 1
  store i8* %incdec.ptr136, i8** %iv, align 8
  store i8 %conv135, i8* %106, align 1
  %107 = load i8*, i8** %ivec.addr, align 8
  store i8* %107, i8** %iv, align 8
  br label %if.end137

if.end137:                                        ; preds = %if.then73, %while.body70
  %108 = load i8*, i8** %in.addr, align 8
  %incdec.ptr138 = getelementptr inbounds i8, i8* %108, i32 1
  store i8* %incdec.ptr138, i8** %in.addr, align 8
  %109 = load i8, i8* %108, align 1
  store i8 %109, i8* %cc, align 1
  %110 = load i8*, i8** %iv, align 8
  %111 = load i32, i32* %n, align 4
  %idxprom139 = sext i32 %111 to i64
  %arrayidx140 = getelementptr inbounds i8, i8* %110, i64 %idxprom139
  %112 = load i8, i8* %arrayidx140, align 1
  store i8 %112, i8* %c, align 1
  %113 = load i8, i8* %cc, align 1
  %114 = load i8*, i8** %iv, align 8
  %115 = load i32, i32* %n, align 4
  %idxprom141 = sext i32 %115 to i64
  %arrayidx142 = getelementptr inbounds i8, i8* %114, i64 %idxprom141
  store i8 %113, i8* %arrayidx142, align 1
  %116 = load i8, i8* %c, align 1
  %conv143 = zext i8 %116 to i32
  %117 = load i8, i8* %cc, align 1
  %conv144 = zext i8 %117 to i32
  %xor145 = xor i32 %conv143, %conv144
  %conv146 = trunc i32 %xor145 to i8
  %118 = load i8*, i8** %out.addr, align 8
  %incdec.ptr147 = getelementptr inbounds i8, i8* %118, i32 1
  store i8* %incdec.ptr147, i8** %out.addr, align 8
  store i8 %conv146, i8* %118, align 1
  %119 = load i32, i32* %n, align 4
  %add148 = add nsw i32 %119, 1
  %and149 = and i32 %add148, 7
  store i32 %and149, i32* %n, align 4
  br label %while.cond67

while.end150:                                     ; preds = %while.cond67
  br label %if.end151

if.end151:                                        ; preds = %while.end150, %while.end
  store i8 0, i8* %cc, align 1
  store i8 0, i8* %c, align 1
  store i64 0, i64* %t, align 8
  %arrayidx152 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 1
  store i64 0, i64* %arrayidx152, align 8
  %arrayidx153 = getelementptr inbounds [2 x i64], [2 x i64]* %ti, i64 0, i64 0
  store i64 0, i64* %arrayidx153, align 16
  store i64 0, i64* %v1, align 8
  store i64 0, i64* %v0, align 8
  %120 = load i32, i32* %n, align 4
  %121 = load i32*, i32** %num.addr, align 8
  store i32 %120, i32* %121, align 4
  ret void
}

; Function Attrs: noinline nounwind ssp uwtable
define i32 @blowfish_main() #0 {
entry:
  %ukey = alloca [8 x i8], align 1
  %indata = alloca [40 x i8], align 16
  %outdata = alloca [40 x i8], align 16
  %ivec = alloca [8 x i8], align 1
  %num = alloca i32, align 4
  %i = alloca i32, align 4
  %j = alloca i32, align 4
  %k = alloca i32, align 4
  %l = alloca i32, align 4
  %encordec = alloca i32, align 4
  %check = alloca i32, align 4
  store i32 0, i32* %num, align 4
  store i32 0, i32* %k, align 4
  store i32 0, i32* %l, align 4
  store i32 1, i32* %encordec, align 4
  store i32 0, i32* %check, align 4
  store i32 0, i32* %i, align 4
  br label %for.cond

for.cond:                                         ; preds = %for.inc, %entry
  %0 = load i32, i32* %i, align 4
  %cmp = icmp slt i32 %0, 8
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %1 = load i32, i32* %i, align 4
  %idxprom = sext i32 %1 to i64
  %arrayidx = getelementptr inbounds [8 x i8], [8 x i8]* %ukey, i64 0, i64 %idxprom
  store i8 0, i8* %arrayidx, align 1
  %2 = load i32, i32* %i, align 4
  %idxprom1 = sext i32 %2 to i64
  %arrayidx2 = getelementptr inbounds [8 x i8], [8 x i8]* %ivec, i64 0, i64 %idxprom1
  store i8 0, i8* %arrayidx2, align 1
  br label %for.inc

for.inc:                                          ; preds = %for.body
  %3 = load i32, i32* %i, align 4
  %inc = add nsw i32 %3, 1
  store i32 %inc, i32* %i, align 4
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %arraydecay = getelementptr inbounds [8 x i8], [8 x i8]* %ukey, i32 0, i32 0
  call void @BF_set_key(i32 8, i8* %arraydecay)
  store i32 0, i32* %i, align 4
  br label %while.cond

while.cond:                                       ; preds = %for.end32, %for.end
  %4 = load i32, i32* %k, align 4
  %cmp3 = icmp slt i32 %4, 5200
  br i1 %cmp3, label %while.body, label %while.end33

while.body:                                       ; preds = %while.cond
  br label %while.cond4

while.cond4:                                      ; preds = %while.body7, %while.body
  %5 = load i32, i32* %k, align 4
  %cmp5 = icmp slt i32 %5, 5200
  br i1 %cmp5, label %land.rhs, label %land.end

land.rhs:                                         ; preds = %while.cond4
  %6 = load i32, i32* %i, align 4
  %cmp6 = icmp slt i32 %6, 40
  br label %land.end

land.end:                                         ; preds = %land.rhs, %while.cond4
  %7 = phi i1 [ false, %while.cond4 ], [ %cmp6, %land.rhs ]
  br i1 %7, label %while.body7, label %while.end

while.body7:                                      ; preds = %land.end
  %8 = load i32, i32* %k, align 4
  %inc8 = add nsw i32 %8, 1
  store i32 %inc8, i32* %k, align 4
  %idxprom9 = sext i32 %8 to i64
  %arrayidx10 = getelementptr inbounds [5200 x i8], [5200 x i8]* @in_key, i64 0, i64 %idxprom9
  %9 = load i8, i8* %arrayidx10, align 1
  %10 = load i32, i32* %i, align 4
  %inc11 = add nsw i32 %10, 1
  store i32 %inc11, i32* %i, align 4
  %idxprom12 = sext i32 %10 to i64
  %arrayidx13 = getelementptr inbounds [40 x i8], [40 x i8]* %indata, i64 0, i64 %idxprom12
  store i8 %9, i8* %arrayidx13, align 1
  br label %while.cond4

while.end:                                        ; preds = %land.end
  %arraydecay14 = getelementptr inbounds [40 x i8], [40 x i8]* %indata, i32 0, i32 0
  %arraydecay15 = getelementptr inbounds [40 x i8], [40 x i8]* %outdata, i32 0, i32 0
  %11 = load i32, i32* %i, align 4
  %conv = sext i32 %11 to i64
  %arraydecay16 = getelementptr inbounds [8 x i8], [8 x i8]* %ivec, i32 0, i32 0
  %12 = load i32, i32* %encordec, align 4
  call void @BF_cfb64_encrypt(i8* %arraydecay14, i8* %arraydecay15, i64 %conv, i8* %arraydecay16, i32* %num, i32 %12)
  store i32 0, i32* %j, align 4
  br label %for.cond17

for.cond17:                                       ; preds = %for.inc30, %while.end
  %13 = load i32, i32* %j, align 4
  %14 = load i32, i32* %i, align 4
  %cmp18 = icmp slt i32 %13, %14
  br i1 %cmp18, label %for.body20, label %for.end32

for.body20:                                       ; preds = %for.cond17
  %15 = load i32, i32* %j, align 4
  %idxprom21 = sext i32 %15 to i64
  %arrayidx22 = getelementptr inbounds [40 x i8], [40 x i8]* %outdata, i64 0, i64 %idxprom21
  %16 = load i8, i8* %arrayidx22, align 1
  %conv23 = zext i8 %16 to i32
  %17 = load i32, i32* %l, align 4
  %inc24 = add nsw i32 %17, 1
  store i32 %inc24, i32* %l, align 4
  %idxprom25 = sext i32 %17 to i64
  %arrayidx26 = getelementptr inbounds [5200 x i8], [5200 x i8]* @out_key, i64 0, i64 %idxprom25
  %18 = load i8, i8* %arrayidx26, align 1
  %conv27 = zext i8 %18 to i32
  %cmp28 = icmp ne i32 %conv23, %conv27
  %conv29 = zext i1 %cmp28 to i32
  %19 = load i32, i32* %check, align 4
  %add = add nsw i32 %19, %conv29
  store i32 %add, i32* %check, align 4
  br label %for.inc30

for.inc30:                                        ; preds = %for.body20
  %20 = load i32, i32* %j, align 4
  %inc31 = add nsw i32 %20, 1
  store i32 %inc31, i32* %j, align 4
  br label %for.cond17

for.end32:                                        ; preds = %for.cond17
  store i32 0, i32* %i, align 4
  br label %while.cond

while.end33:                                      ; preds = %while.cond
  %21 = load i32, i32* %check, align 4
  ret i32 %21
}

; Function Attrs: noinline nounwind ssp uwtable
define i32 @main() #0 {
entry:
  %retval = alloca i32, align 4
  %t_begin = alloca i64, align 8
  %main_result = alloca i32, align 4
  %t_end = alloca i64, align 8
  %time_taken = alloca double, align 8
  store i32 0, i32* %retval, align 4
  %call = call i64 @"\01_clock"()
  store i64 %call, i64* %t_begin, align 8
  store i32 0, i32* %main_result, align 4
  %call1 = call i32 @blowfish_main()
  store i32 %call1, i32* %main_result, align 4
  %call2 = call i64 @"\01_clock"()
  store i64 %call2, i64* %t_end, align 8
  %0 = load i64, i64* %t_end, align 8
  %conv = uitofp i64 %0 to double
  %1 = load i64, i64* %t_begin, align 8
  %conv3 = uitofp i64 %1 to double
  %sub = fsub double %conv, %conv3
  %div = fdiv double %sub, 1.000000e+06
  store double %div, double* %time_taken, align 8
  %2 = load double, double* %time_taken, align 8
  %call4 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str, i32 0, i32 0), double %2)
  %3 = load i32, i32* %main_result, align 4
  %call5 = call i32 (i8*, ...) @printf(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.1, i32 0, i32 0), i32 %3)
  %4 = load i32, i32* %main_result, align 4
  ret i32 %4
}

declare i64 @"\01_clock"() #1

declare i32 @printf(i8*, ...) #1

attributes #0 = { noinline nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="penryn" "target-features"="+cx16,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="penryn" "target-features"="+cx16,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"PIC Level", i32 2}
!1 = !{!"clang version 4.0.0 (tags/RELEASE_400/final)"}
